{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Twitter the-algorithm source code with LangChain, GPT4 and Deep Lake\n",
    "In this tutorial, we are going to use Langchain + Deep Lake with GPT4 to analyze the code base of the twitter algorithm. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define OpenAI embeddings, Deep Lake multi-modal vector store api and authenticate. For full documentation of Deep Lake please follow [docs](https://docs.activeloop.ai/) and [API reference](https://docs.deeplake.ai/en/latest/).\n",
    "\n",
    "Authenticate into Deep Lake if you want to create your own dataset and publish it. You can get an API key from the [platform](https://app.activeloop.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMERS_CACHE=\"/f/C/cache/huggingface/hub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm as notebook_tqdm\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "os.environ['TRANSFORMERS_CACHE'] = 'F:\\C\\cache\\huggingface\\hub'\n",
    "os.environ['ACTIVELOOP_TOKEN'] = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "model_name = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all files inside the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "import tiktoken\n",
    "\n",
    "root_dir = '../sources-repositories/langchain'  # Declare root directory variable\n",
    "docs = []  # Create empty list for documents\n",
    "\n",
    "pdf_loader = PyPDFLoader('..sources-documents/Talks-with-Sri-Ramana-Maharshi--complete.pdf')  # Use PDFLoader to load and split the PDF file's content\n",
    "docs.extend(pdf_loader.load()) # just load, don't split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='31Talks with Sri Ramana Maharshi\\n(a) Is omniscience of God consistent with ego’s freewill?\\n(b) Is omnipotence of God consistent with ego’s freewill?\\n(c) Are the natural laws consistent with God’s free-will?\\nM.: Yes. Free-will is the present appearing to a limited faculty of \\nsight and will. The same ego sees its past activity as falling into a \\ncourse of ‘law’ or rules - its own free-will being one of the links \\nin that course of law.\\nOmnipotence and omniscience of God are then seen by the ego to \\nhave acted through the appearance of his own free-will. So he comes \\nto the conclusion that the ego must go by appearances. Natural laws \\nare manifestations of God’s will and they have been laid down.\\nD.: Is the study of science, psychology, physiology, philosophy, etc. \\nhelpful for:-\\n(1) this art of yoga-liberation.\\n(2) the intuitive grasp of the unity of the Real?\\nM.: Very little. Some knowledge is needed for yoga and it may be \\nfound in books. But practical application is the thing needed, and \\npersonal example, personal touch and personal instructions are the \\nmost helpful aids. As for the other, a person may laboriously convince \\nhimself of the truth to be intuited, i.e., its function and nature, but the \\nactual intuition is akin to feeling and requires practice and personal \\ncontact. Mere book learning is not of any great use. After realisation \\nall intellectual loads are useless burdens and are thrown overboard \\nas jetsam. Jettisoning the ego is necessary and natural.\\nD.: How does dream differ from waking?\\nM.: In dreams one takes on different bodies, and they re-enter this \\nbody when one dreams of sense-contacts.\\nD.: What is happiness? Is it inhering in the Atman or in the object, or \\nin the contact between the subject and the object? But we do not \\nsee happiness in our affairs. When does It actually arise?\\nM.: When there is contact of a desirable sort or memory thereof, \\nand when there is freedom from undesirable contacts or memory \\nthereof, we say there is happiness. Such happiness is relative and \\nis better called pleasure.' metadata={'source': '../Talks-with-Sri-Ramana-Maharshi--complete.pdf', 'page': 40}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mlen\u001b[39m(docs) \u001b[39m# number of processed document pages\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(docs[\u001b[39m40\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m pg_40 \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49msub(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39md\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m1,3}Talks with Sri Ramana Maharshi\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, docs[\u001b[39m40\u001b[39;49m])\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(pg_40)\n",
      "File \u001b[1;32mf:\\ProgramData\\miniconda3\\envs\\github-qa-langchain\\lib\\re.py:210\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msub(repl, string, count)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "len(docs) # number of processed document pages\n",
    "print(docs[40]) # returns 31Talks with Sri Ramana Maharshi\\n(a) Is omniscience of God consis ....\n",
    "\n",
    "# Use regex to remove \"31Talks with Sri Ramana Maharshi\\n\"\n",
    "pg_40 =\n",
    "print(pg_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Token Length in Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0\n",
      "Avg: 490\n",
      "Max: 812\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_counts = [tiktoken_len(doc.page_content) for doc in docs]\n",
    "\n",
    "print(f\"\"\"Min: {min(token_counts)}\n",
    "Avg: {int(sum(token_counts) / len(token_counts))}\n",
    "Max: {max(token_counts)}\"\"\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set style and color palette for the plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "# create histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(token_counts, kde=False, bins=50)\n",
    "\n",
    "# customize the plot info\n",
    "plt.title(\"Token Counts Histogram\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, chunk the files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Chunking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,  # number of tokens overlap between chunks\n",
    "    length_function=tiktoken_len,\n",
    "    separators=['\\n\\n', '\\n', ' ', '']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='16Talks with Sri Ramana Maharshi\\nD.: They say that there are many saints in Tibet who remain in solitude \\nand are still very helpful to the world. How can it be?\\nM.: It can be so. Realisation of the Self is the greatest help that can be \\nrendered to humanity. Therefore, the saints are said to be helpful, \\nthough they remain in forests. But it should not be forgotten that \\nsolitude is not in forests only. It can be had even in towns, in the \\nthick of worldly occupations.\\nD.: It is not necessary that the saints should mix with people and be \\nhelpful to them?\\nM.: The Self alone is the Reality; the world and the rest of it are not. The \\nrealised being does not see the world as different from himself.\\nD.: Thus then, the saint’s realisation leads to the uplift of humanity \\nwithout the latter being aware of it. Is it so?\\nM.: Yes. The help is imperceptible but is still there. A saint helps the \\nwhole of humanity, unknown to the latter.\\nD.: Would it not be better if he mixed with others?\\nM.: There are no others to mix with. The Self is the one and only \\nReality.\\nD.: If there be a hundred Self-realised men will it not be to the greater \\nbenefit of the world?\\nM.: When you say ‘Self’ you refer to the unlimited, but when you add \\n‘men’ to it, you limit the meaning. There is only one Infinite Self.\\nD.: Yes, yes, I see! Sri Krishna has said in the Gita that work must \\nbe performed without attachment and such work is better than \\nidleness. Is it Karma Yoga?\\nM.: What is said is given out to suit the temperament of the hearers.\\nD.: In Europe it is not understood by the people that a man in solitude \\ncan be helpful. They imagine that men working in the world can \\nalone be useful. When will this confusion cease? Will the European \\nmind continue wading in the morass or will it realise the truth?\\nM.: Never mind Europe or America. Where are they except in your \\nmind? Realise your Self and then all is realised.\\nIf you dream and see several men, and then wake up and recall \\nyour dream, do you try to ascertain if the persons of your dream \\ncreation are also awake?' metadata={'source': '../Talks-with-Sri-Ramana-Maharshi--complete.pdf', 'page': 25}\n"
     ]
    }
   ],
   "source": [
    "print(docs[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407e501034da4a34920ec1564204411d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hashlib\n",
    "m = hashlib.md5()  # this will convert URL into unique ID\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.docstore.document import Document\n",
    "documents = []\n",
    "\n",
    "for doc in tqdm(docs):\n",
    "    url = doc.metadata['source'].replace('../dev/langchain/langchain\\\\', 'https://github.com/hwchase17/langchain/tree/master/langchain/')\n",
    "    m.update(url.encode('utf-8'))\n",
    "    uid = m.hexdigest()[:12]\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        documents.append(\n",
    "            Document(\n",
    "                page_content=re.sub(r'\\d{1,3}Talks with Sri Ramana Maharshi\\n', '', chunk),\n",
    "                metadata={\n",
    "                    'id': f'{uid}-{i}',\n",
    "                    'source': url\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "            # {'text': chunk})\n",
    "        # documents.append({\n",
    "        #     'id': f'{uid}-{i}',\n",
    "        #     'text': chunk,\n",
    "        #     'source': url\n",
    "        # })\n",
    "        # documents.extend(f\"id={uid}-{i}\")\n",
    "        # documents.extend('text={chunk}')\n",
    "        # documents.extend('source={url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='16Talks with Sri Ramana Maharshi\\nD.: They say that there are many saints in Tibet who remain in solitude \\nand are still very helpful to the world. How can it be?\\nM.: It can be so. Realisation of the Self is the greatest help that can be \\nrendered to humanity. Therefore, the saints are said to be helpful, \\nthough they remain in forests. But it should not be forgotten that \\nsolitude is not in forests only. It can be had even in towns, in the \\nthick of worldly occupations.\\nD.: It is not necessary that the saints should mix with people and be \\nhelpful to them?\\nM.: The Self alone is the Reality; the world and the rest of it are not. The \\nrealised being does not see the world as different from himself.\\nD.: Thus then, the saint’s realisation leads to the uplift of humanity \\nwithout the latter being aware of it. Is it so?\\nM.: Yes. The help is imperceptible but is still there. A saint helps the \\nwhole of humanity, unknown to the latter.\\nD.: Would it not be better if he mixed with others?\\nM.: There are no others to mix with. The Self is the one and only \\nReality.\\nD.: If there be a hundred Self-realised men will it not be to the greater \\nbenefit of the world?\\nM.: When you say ‘Self’ you refer to the unlimited, but when you add \\n‘men’ to it, you limit the meaning. There is only one Infinite Self.\\nD.: Yes, yes, I see! Sri Krishna has said in the Gita that work must \\nbe performed without attachment and such work is better than \\nidleness. Is it Karma Yoga?\\nM.: What is said is given out to suit the temperament of the hearers.\\nD.: In Europe it is not understood by the people that a man in solitude \\ncan be helpful. They imagine that men working in the world can \\nalone be useful. When will this confusion cease? Will the European \\nmind continue wading in the morass or will it realise the truth?\\nM.: Never mind Europe or America. Where are they except in your \\nmind? Realise your Self and then all is realised.\\nIf you dream and see several men, and then wake up and recall \\nyour dream, do you try to ascertain if the persons of your dream \\ncreation are also awake?' metadata={'source': '../Talks-with-Sri-Ramana-Maharshi--complete.pdf', 'page': 25}\n"
     ]
    }
   ],
   "source": [
    "len(documents)\n",
    "print(docs[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='\"\"\"Beta Feature: base interface for cache.\"\"\"\\nimport json\\nfrom abc import ABC, abstractmethod\\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\\n\\nfrom sqlalchemy import Column, Integer, String, create_engine, select\\nfrom sqlalchemy.engine.base import Engine\\nfrom sqlalchemy.orm import Session\\n\\ntry:\\n    from sqlalchemy.orm import declarative_base\\nexcept ImportError:\\n    from sqlalchemy.ext.declarative import declarative_base\\n\\nfrom langchain.schema import Generation\\n\\nRETURN_VAL_TYPE = List[Generation]\\n\\n\\nclass BaseCache(ABC):\\n    \"\"\"Base interface for cache.\"\"\"\\n\\n    @abstractmethod\\n    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\\n        \"\"\"Look up based on prompt and llm_string.\"\"\"\\n\\n    @abstractmethod\\n    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\\n        \"\"\"Update cache based on prompt and llm_string.\"\"\"\\n\\n\\nclass InMemoryCache(BaseCache):\\n    \"\"\"Cache that stores things in memory.\"\"\"' metadata={'source': '../dev/langchain/langchain\\\\cache.py'}\n",
      "<class 'langchain.schema.Document'>\n",
      "page_content='TALKS \\nWITH \\nSRI RAMANA  MAHARSHI\\nSRI RAMANASRAMAM\\nTiruvannamalai\\n2006' metadata={'id': 'cb9055527713-0', 'source': '../Talks-with-Sri-Ramana-Maharshi--complete.pdf'}\n",
      "<class 'langchain.schema.Document'>\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the indexing. This will take about ~4 mins to compute embeddings and upload to Activeloop. You can then publish the dataset to be public."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"langchain_v2\"\n",
    "\n",
    "content_source = documents\n",
    "# content_source = text   # Old chunking method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local vector store\n",
    "\n",
    "Stored in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem://langchain_v2 loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "Evaluating ingest: 0%|          | 0/2 [00:00<?"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c75c6b670e4a5abe5005c58fc87db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "Evaluating ingest: 50%|█████     | 1/2 [00:21<00:21"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3596d967698442ca8c805ad437fa9c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████| 2/2 [00:32<00:00\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='mem://langchain_v2', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape      dtype  compression\n",
      "  -------   -------    -------    -------  ------- \n",
      " embedding  generic  (1352, 768)  float32   None   \n",
      "    ids      text     (1352, 1)     str     None   \n",
      " metadata    json     (1352, 1)     str     None   \n",
      "   text      text     (1352, 1)     str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import deeplake\n",
    "db = DeepLake.from_documents(content_source, embeddings, dataset_path=f\"mem://{database_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote storage\n",
    "\n",
    "Uses Activeloop API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ACTIVELOOP_TOKEN'] = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "db = DeepLake.from_documents(content_source, embeddings, dataset_path=f\"hub://deadbranches/{database_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem://langchain_v2 loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(dataset_path=f\"mem://{database_name}\", read_only=True, embedding_function=embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DeepLake(dataset_path=f\"hub://deadbranches/{database_name}\", read_only=True, embedding_function=embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Question Answering on Twitter algorithm codebase\n",
    "First load the dataset, construct the retriever, then construct the Conversational Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'dot'\n",
    "retriever.search_kwargs['fetch_k'] = 100\n",
    "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "retriever.search_kwargs['k'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f477e401f94bf0a50deafd48a67f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:  https://github.com/hwchase17/langchain/tree/master/langchain/chains\\qa_with_sources\\map_reduce_prompt.py \n",
      "\n",
      "Content:  \n",
      "\"QUESTION: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: 28-pl\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\\\n",
      "\\\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\\\n",
      "\\\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\\\n",
      "\\\n",
      "11.9 No Third-Party Beneficiaries.\n",
      "Source: 30-pl\n",
      "Content: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\n",
      "Source: 4-pl\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: 28-pl\"\n",
      "\n",
      "\n",
      "\n",
      "Source:  https://github.com/hwchase17/langchain/tree/master/langchain/output_parsers\\prompts.py \n",
      "\n",
      "Content:  \n",
      "\"# flake8: noqa\n",
      "from langchain.prompts.prompt import PromptTemplate\n",
      "\n",
      "NAIVE_FIX = \"\"\"Instructions:\n",
      "--------------\n",
      "{instructions}\n",
      "--------------\n",
      "Completion:\n",
      "--------------\n",
      "{completion}\n",
      "--------------\n",
      "\n",
      "Above, the Completion did not satisfy the constraints given in the Instructions.\n",
      "Error:\n",
      "--------------\n",
      "{error}\n",
      "--------------\n",
      "\n",
      "Please try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:\"\"\"\n",
      "\n",
      "\n",
      "NAIVE_FIX_PROMPT = PromptTemplate.from_template(NAIVE_FIX)\"\n",
      "\n",
      "\n",
      "\n",
      "Source:  https://github.com/hwchase17/langchain/tree/master/langchain/chains\\question_answering\\map_reduce_prompt.py \n",
      "\n",
      "Content:  \n",
      "\"Content: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\\n",
      "\\\n",
      "To all Americans, I will be honest with you, as I\\u2019ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\\n",
      "\\\n",
      "And I\\u2019m taking robust action to make sure the pain of our sanctions  is targeted at Russia\\u2019s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\\n",
      "\\\n",
      "Tonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\\n",
      "\\\n",
      "America will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\\n",
      "\\\n",
      "These steps will help blunt gas prices here at home. And I know the news about what\\u2019s happening can seem alarming. \\\n",
      "\\\n",
      "But I want you to know that we are going to be okay.\"\n",
      "\n",
      "\n",
      "\n",
      "Source:  https://github.com/hwchase17/langchain/tree/master/langchain/chains\\qa_with_sources\\stuff_prompt.py \n",
      "\n",
      "Content:  \n",
      "\"Source: 5-pl\n",
      "Content: More support for patients and families. \\\n",
      "\\\n",
      "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\\n",
      "\\\n",
      "It\\u2019s based on DARPA\\u2014the Defense Department project that led to the Internet, GPS, and so much more.  \\\n",
      "\\\n",
      "ARPA-H will have a singular purpose\\u2014to drive breakthroughs in cancer, Alzheimer\\u2019s, diabetes, and more. \\\n",
      "\\\n",
      "A unity agenda for the nation. \\\n",
      "\\\n",
      "We can do this. \\\n",
      "\\\n",
      "My fellow Americans\\u2014tonight , we have gathered in a sacred space\\u2014the citadel of our democracy. \\\n",
      "\\\n",
      "In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\\n",
      "\\\n",
      "We have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\\n",
      "\\\n",
      "And built the strongest, freest, and most prosperous nation the world has ever known. \\\n",
      "\\\n",
      "Now is the hour. \\\n",
      "\\\n",
      "Our moment of responsibility. \\\n",
      "\\\n",
      "Our test of resolve and conscience, of history itself. \\\n",
      "\\\n",
      "It is in this moment that our character is formed. Our purpose is found. Our future is forged. \\\n",
      "\\\n",
      "Well I know this nation.\n",
      "Source: 34-pl\n",
      "=========\n",
      "FINAL ANSWER: The president did not mention Michael Jackson.\n",
      "SOURCES:\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "What other methods can I use to search a vector database other than similarity_search?\n",
    "\"\"\"\n",
    "results = db.similarity_search(query, distance_metric='dot', k=4)\n",
    "\n",
    "# print(\"class:\", type(results).__name__)\n",
    "for result in results:\n",
    "    print(f\"Source:  {result.metadata['source']} \")\n",
    "    print(\"\\nContent:  \")\n",
    "    page_content = json.dumps(result.page_content).replace('\\\\n', '\\n').replace('\\\\\"', '\"')\n",
    "    print(page_content)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify user defined functions using [Deep Lake filters](https://docs.deeplake.ai/en/latest/deeplake.core.dataset.html#deeplake.core.dataset.Dataset.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(x):\n",
    "    # filter based on source code\n",
    "    # if 'com.google' in x['text'].data()['value']:\n",
    "    #     return False\n",
    "    \n",
    "    # filter based on path e.g. extension\n",
    "    metadata =  x['metadata'].data()['value']\n",
    "    return 'scala' in metadata['source'] or 'py' in metadata['source']\n",
    "\n",
    "### turn on below for custom filtering\n",
    "# retriever.search_kwargs['filter'] = filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "#model = ChatOpenAI(model='gpt-4') # 'gpt-3.5-turbo',\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo') # 'gpt-3.5-turbo',\n",
    "qa = ConversationalRetrievalChain.from_llm(model,retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78407ad8061944abbb6fe41d763e018d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"messages\": [{\"role\": \"system\", \"content\": \"Use the following pieces of context to answer the users question. \\\\nIf you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\\\n----------------\\\\nHourly Parameter Definition\\\\nThe parameter &hourly= accepts the following values. Most weather variables are given as an instantaneous value for the indicated hour. Some variables like precipitation are calculated from the preceding hour as an average or sum.\\\\n\\\\nHourly Parameter Definition\\\\nThe parameter &hourly= accepts the following values. Most weather variables are given as an instantaneous value for the indicated hour. Some variables like precipitation are calculated from the preceding hour as an average or sum.\\\\n\\\\ndef _default_scripting_text_mapping(\\\\n    dim: int,\\\\n    vector_field: str = \\\\\"vector_field\\\\\",\\\\n) -> Dict:\\\\n    \\\\\"\\\\\"\\\\\"For Painless Scripting or Script Scoring,the default mapping to create index.\\\\\"\\\\\"\\\\\"\\\\n    return {\\\\n        \\\\\"mappings\\\\\": {\\\\n            \\\\\"properties\\\\\": {\\\\n                vector_field: {\\\\\"type\\\\\": \\\\\"knn_vector\\\\\", \\\\\"dimension\\\\\": dim},\\\\n            }\\\\n        }\\\\n    }\\\\n\\\\ndef _default_scripting_text_mapping(\\\\n    dim: int,\\\\n    vector_field: str = \\\\\"vector_field\\\\\",\\\\n) -> Dict:\\\\n    \\\\\"\\\\\"\\\\\"For Painless Scripting or Script Scoring,the default mapping to create index.\\\\\"\\\\\"\\\\\"\\\\n    return {\\\\n        \\\\\"mappings\\\\\": {\\\\n            \\\\\"properties\\\\\": {\\\\n                vector_field: {\\\\\"type\\\\\": \\\\\"knn_vector\\\\\", \\\\\"dimension\\\\\": dim},\\\\n            }\\\\n        }\\\\n    }\\\\n\\\\ndef _default_script_query(\\\\n    query_vector: List[float],\\\\n    space_type: str = \\\\\"l2\\\\\",\\\\n    pre_filter: Dict = MATCH_ALL_QUERY,\\\\n    vector_field: str = \\\\\"vector_field\\\\\",\\\\n) -> Dict:\\\\n    \\\\\"\\\\\"\\\\\"For Script Scoring Search, this is the default query.\\\\\"\\\\\"\\\\\"\\\\n    return {\\\\n        \\\\\"query\\\\\": {\\\\n            \\\\\"script_score\\\\\": {\\\\n                \\\\\"query\\\\\": pre_filter,\\\\n                \\\\\"script\\\\\": {\\\\n                    \\\\\"source\\\\\": \\\\\"knn_score\\\\\",\\\\n                    \\\\\"lang\\\\\": \\\\\"knn\\\\\",\\\\n                    \\\\\"params\\\\\": {\\\\n                        \\\\\"field\\\\\": vector_field,\\\\n                        \\\\\"query_value\\\\\": query_vector,\\\\n                        \\\\\"space_type\\\\\": space_type,\\\\n                    },\\\\n                },\\\\n            }\\\\n        }\\\\n    }\\\\n\\\\ndef _default_script_query(\\\\n    query_vector: List[float],\\\\n    space_type: str = \\\\\"l2\\\\\",\\\\n    pre_filter: Dict = MATCH_ALL_QUERY,\\\\n    vector_field: str = \\\\\"vector_field\\\\\",\\\\n) -> Dict:\\\\n    \\\\\"\\\\\"\\\\\"For Script Scoring Search, this is the default query.\\\\\"\\\\\"\\\\\"\\\\n    return {\\\\n        \\\\\"query\\\\\": {\\\\n            \\\\\"script_score\\\\\": {\\\\n                \\\\\"query\\\\\": pre_filter,\\\\n                \\\\\"script\\\\\": {\\\\n                    \\\\\"source\\\\\": \\\\\"knn_score\\\\\",\\\\n                    \\\\\"lang\\\\\": \\\\\"knn\\\\\",\\\\n                    \\\\\"params\\\\\": {\\\\n                        \\\\\"field\\\\\": vector_field,\\\\n                        \\\\\"query_value\\\\\": query_vector,\\\\n                        \\\\\"space_type\\\\\": space_type,\\\\n                    },\\\\n                },\\\\n            }\\\\n        }\\\\n    }\\\\n\\\\ndef similarity_search_with_score(\\\\n        self, query: str, k: int = 4\\\\n    ) -> List[Tuple[Document, float]]:\\\\n        \\\\\"\\\\\"\\\\\"Return docs most similar to query.\\\\n\\\\n        Args:\\\\n            query: Text to look up documents similar to.\\\\n            k: Number of Documents to return. Defaults to 4.\\\\n\\\\n        Returns:\\\\n            List of Documents most similar to the query and score for each\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        try:\\\\n            from redis.commands.search.query import Query\\\\n        except ImportError:\\\\n            raise ValueError(\\\\n                \\\\\"Could not import redis python package. \\\\\"\\\\n                \\\\\"Please install it with `pip install redis`.\\\\\"\\\\n            )\\\\n\\\\n        # Creates embedding vector from user query\\\\n        embedding = self.embedding_function(query)\\\\n\\\\ndef similarity_search_with_score(\\\\n        self, query: str, k: int = 4\\\\n    ) -> List[Tuple[Document, float]]:\\\\n        \\\\\"\\\\\"\\\\\"Return docs most similar to query.\\\\n\\\\n        Args:\\\\n            query: Text to look up documents similar to.\\\\n            k: Number of Documents to return. Defaults to 4.\\\\n\\\\n        Returns:\\\\n            List of Documents most similar to the query and score for each\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        try:\\\\n            from redis.commands.search.query import Query\\\\n        except ImportError:\\\\n            raise ValueError(\\\\n                \\\\\"Could not import redis python package. \\\\\"\\\\n                \\\\\"Please install it with `pip install redis`.\\\\\"\\\\n            )\\\\n\\\\n        # Creates embedding vector from user query\\\\n        embedding = self.embedding_function(query)\\\\n\\\\nBy default supports Approximate Search.\\\\n        Also supports Script Scoring and Painless Scripting.\\\\n\\\\n        Args:\\\\n            query: Text to look up documents similar to.\\\\n            k: Number of Documents to return. Defaults to 4.\\\\n\\\\n        Returns:\\\\n            List of Documents most similar to the query.\\\\n\\\\n        Optional Args:\\\\n            vector_field: Document field embeddings are stored in. Defaults to\\\\n            \\\\\"vector_field\\\\\".\\\\n\\\\n            text_field: Document field the text of the document is stored in. Defaults\\\\n            to \\\\\"text\\\\\".\\\\n\\\\n            metadata_field: Document field that metadata is stored in. Defaults to\\\\n            \\\\\"metadata\\\\\".\\\\n            Can be set to a special value \\\\\"*\\\\\" to include the entire document.\\\\n\\\\n        Optional Args for Approximate Search:\\\\n            search_type: \\\\\"approximate_search\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            size: number of results the query actually returns; default: 4\\\\n\\\\nBy default supports Approximate Search.\\\\n        Also supports Script Scoring and Painless Scripting.\\\\n\\\\n        Args:\\\\n            query: Text to look up documents similar to.\\\\n            k: Number of Documents to return. Defaults to 4.\\\\n\\\\n        Returns:\\\\n            List of Documents most similar to the query.\\\\n\\\\n        Optional Args:\\\\n            vector_field: Document field embeddings are stored in. Defaults to\\\\n            \\\\\"vector_field\\\\\".\\\\n\\\\n            text_field: Document field the text of the document is stored in. Defaults\\\\n            to \\\\\"text\\\\\".\\\\n\\\\n            metadata_field: Document field that metadata is stored in. Defaults to\\\\n            \\\\\"metadata\\\\\".\\\\n            Can be set to a special value \\\\\"*\\\\\" to include the entire document.\\\\n\\\\n        Optional Args for Approximate Search:\\\\n            search_type: \\\\\"approximate_search\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            size: number of results the query actually returns; default: 4\\\\n\\\\ndef print_text(text: str, color: Optional[str] = None, end: str = \\\\\"\\\\\") -> None:\\\\n    \\\\\"\\\\\"\\\\\"Print text with highlighting and no end characters.\\\\\"\\\\\"\\\\\"\\\\n    if color is None:\\\\n        text_to_print = text\\\\n    else:\\\\n        text_to_print = get_colored_text(text, color)\\\\n    print(text_to_print, end=end)\\\\n\\\\ndef print_text(text: str, color: Optional[str] = None, end: str = \\\\\"\\\\\") -> None:\\\\n    \\\\\"\\\\\"\\\\\"Print text with highlighting and no end characters.\\\\\"\\\\\"\\\\\"\\\\n    if color is None:\\\\n        text_to_print = text\\\\n    else:\\\\n        text_to_print = get_colored_text(text, color)\\\\n    print(text_to_print, end=end)\\\\n\\\\nOptional Args for Script Scoring Search:\\\\n            search_type: \\\\\"script_scoring\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            space_type: \\\\\"l2\\\\\", \\\\\"l1\\\\\", \\\\\"linf\\\\\", \\\\\"cosinesimil\\\\\", \\\\\"innerproduct\\\\\",\\\\n            \\\\\"hammingbit\\\\\"; default: \\\\\"l2\\\\\"\\\\n\\\\n            pre_filter: script_score query to pre-filter documents before identifying\\\\n            nearest neighbors; default: {\\\\\"match_all\\\\\": {}}\\\\n\\\\n        Optional Args for Painless Scripting Search:\\\\n            search_type: \\\\\"painless_scripting\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            space_type: \\\\\"l2Squared\\\\\", \\\\\"l1Norm\\\\\", \\\\\"cosineSimilarity\\\\\"; default: \\\\\"l2Squared\\\\\"\\\\n\\\\nOptional Args for Script Scoring Search:\\\\n            search_type: \\\\\"script_scoring\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            space_type: \\\\\"l2\\\\\", \\\\\"l1\\\\\", \\\\\"linf\\\\\", \\\\\"cosinesimil\\\\\", \\\\\"innerproduct\\\\\",\\\\n            \\\\\"hammingbit\\\\\"; default: \\\\\"l2\\\\\"\\\\n\\\\n            pre_filter: script_score query to pre-filter documents before identifying\\\\n            nearest neighbors; default: {\\\\\"match_all\\\\\": {}}\\\\n\\\\n        Optional Args for Painless Scripting Search:\\\\n            search_type: \\\\\"painless_scripting\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            space_type: \\\\\"l2Squared\\\\\", \\\\\"l1Norm\\\\\", \\\\\"cosineSimilarity\\\\\"; default: \\\\\"l2Squared\\\\\"\\\\n\\\\nReturns:\\\\n            bool: Whether or not the drop was successful.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        redis_url = get_from_dict_or_env(kwargs, \\\\\"redis_url\\\\\", \\\\\"REDIS_URL\\\\\")\\\\n        try:\\\\n            import redis\\\\n        except ImportError:\\\\n            raise ValueError(\\\\n                \\\\\"Could not import redis python package. \\\\\"\\\\n                \\\\\"Please install it with `pip install redis`.\\\\\"\\\\n            )\\\\n        try:\\\\n            # We need to first remove redis_url from kwargs,\\\\n            # otherwise passing it to Redis will result in an error.\\\\n            kwargs.pop(\\\\\"redis_url\\\\\")\\\\n            client = redis.from_url(url=redis_url, **kwargs)\\\\n        except ValueError as e:\\\\n            raise ValueError(f\\\\\"Your redis connected error: {e}\\\\\")\\\\n        # Check if index exists\\\\n        try:\\\\n            client.ft(index_name).dropindex(delete_documents)\\\\n            logger.info(\\\\\"Drop index\\\\\")\\\\n            return True\\\\n        except:  # noqa: E722\\\\n            # Index not exist\\\\n            return False\\\\n\\\\nReturns:\\\\n            bool: Whether or not the drop was successful.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        redis_url = get_from_dict_or_env(kwargs, \\\\\"redis_url\\\\\", \\\\\"REDIS_URL\\\\\")\\\\n        try:\\\\n            import redis\\\\n        except ImportError:\\\\n            raise ValueError(\\\\n                \\\\\"Could not import redis python package. \\\\\"\\\\n                \\\\\"Please install it with `pip install redis`.\\\\\"\\\\n            )\\\\n        try:\\\\n            # We need to first remove redis_url from kwargs,\\\\n            # otherwise passing it to Redis will result in an error.\\\\n            kwargs.pop(\\\\\"redis_url\\\\\")\\\\n            client = redis.from_url(url=redis_url, **kwargs)\\\\n        except ValueError as e:\\\\n            raise ValueError(f\\\\\"Your redis connected error: {e}\\\\\")\\\\n        # Check if index exists\\\\n        try:\\\\n            client.ft(index_name).dropindex(delete_documents)\\\\n            logger.info(\\\\\"Drop index\\\\\")\\\\n            return True\\\\n        except:  # noqa: E722\\\\n            # Index not exist\\\\n            return False\\\\n\\\\ndef _get_driver(self) -> Union[\\\\\"Chrome\\\\\", \\\\\"Firefox\\\\\"]:\\\\n        \\\\\"\\\\\"\\\\\"Create and return a WebDriver instance based on the specified browser.\\\\n\\\\n        Raises:\\\\n            ValueError: If an invalid browser is specified.\\\\n\\\\n        Returns:\\\\n            Union[Chrome, Firefox]: A WebDriver instance for the specified browser.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        if self.browser.lower() == \\\\\"chrome\\\\\":\\\\n            from selenium.webdriver import Chrome\\\\n            from selenium.webdriver.chrome.options import Options as ChromeOptions\\\\n\\\\ndef _get_driver(self) -> Union[\\\\\"Chrome\\\\\", \\\\\"Firefox\\\\\"]:\\\\n        \\\\\"\\\\\"\\\\\"Create and return a WebDriver instance based on the specified browser.\\\\n\\\\n        Raises:\\\\n            ValueError: If an invalid browser is specified.\\\\n\\\\n        Returns:\\\\n            Union[Chrome, Firefox]: A WebDriver instance for the specified browser.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        if self.browser.lower() == \\\\\"chrome\\\\\":\\\\n            from selenium.webdriver import Chrome\\\\n            from selenium.webdriver.chrome.options import Options as ChromeOptions\\\\n\\\\nelse:\\\\n            toret = \\\\\"No good search result found\\\\\"\\\\n        return toret\\\\n\\\\nelse:\\\\n            toret = \\\\\"No good search result found\\\\\"\\\\n        return toret\"}, {\"role\": \"user\", \"content\": \"How do I load a 4bit quantized LLaMA model into langchain for inference tasks? The model was quantized using GPTQ, and has a group size of 128?\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.7}' message='Post details'\n",
      "DEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "DEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4838 request_id=3111b5c1c9fe6d25c9d28525dc37bd8f response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: How do I load a 4bit quantized LLaMA model into langchain for inference tasks? The model was quantized using GPTQ, and has a group size of 128? \n",
      "\n",
      "**Answer**: I'm sorry, but I am not familiar with the Langchain framework or with the GPTQ quantization method. Without more information, I cannot provide an accurate answer to your question. Can you provide more details or context about what you are trying to do? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"How do I load a 4bit quantized LLaMA model into langchain for inference tasks? The model was quantized using GPTQ, and has a group size of 128?\",\n",
    "] \n",
    "chat_history = []\n",
    "\n",
    "# for question in questions:  \n",
    "#     result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "#     print(result)\n",
    "\n",
    "for question in questions:  \n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> **Question**: What does favCountParams do? \n",
    "\n",
    "**Answer**: `favCountParams` is an optional ThriftLinearFeatureRankingParams instance that represents the parameters related to the \"favorite count\" feature in the ranking process. It is used to control the weight of the favorite count feature while ranking tweets. The favorite count is the number of times a tweet has been marked as a favorite by users, and it is considered an important signal in the ranking of tweets. By using `favCountParams`, the system can adjust the importance of the favorite count while calculating the final ranking score of a tweet. \n",
    "\n",
    "-> **Question**: is it Likes + Bookmarks, or not clear from the code?\n",
    "\n",
    "**Answer**: From the provided code, it is not clear if the favorite count metric is determined by the sum of likes and bookmarks. The favorite count is mentioned in the code, but there is no explicit reference to how it is calculated in terms of likes and bookmarks. \n",
    "\n",
    "-> **Question**: What are the major negative modifiers that lower your linear ranking parameters?\n",
    "\n",
    "**Answer**: In the given code, major negative modifiers that lower the linear ranking parameters are:\n",
    "\n",
    "1. `scoringData.querySpecificScore`: This score adjustment is based on the query-specific information. If its value is negative, it will lower the linear ranking parameters.\n",
    "\n",
    "2. `scoringData.authorSpecificScore`: This score adjustment is based on the author-specific information. If its value is negative, it will also lower the linear ranking parameters.\n",
    "\n",
    "Please note that I cannot provide more information on the exact calculations of these negative modifiers, as the code for their determination is not provided. \n",
    "\n",
    "-> **Question**: How do you get assigned to SimClusters?\n",
    "\n",
    "**Answer**: The assignment to SimClusters occurs through a Metropolis-Hastings sampling-based community detection algorithm that is run on the Producer-Producer similarity graph. This graph is created by computing the cosine similarity scores between the users who follow each producer. The algorithm identifies communities or clusters of Producers with similar followers, and takes a parameter *k* for specifying the number of communities to be detected.\n",
    "\n",
    "After the community detection, different users and content are represented as sparse, interpretable vectors within these identified communities (SimClusters). The resulting SimClusters embeddings can be used for various recommendation tasks. \n",
    "\n",
    "-> **Question**: What is needed to migrate from one SimClusters to another SimClusters?\n",
    "\n",
    "**Answer**: To migrate from one SimClusters representation to another, you can follow these general steps:\n",
    "\n",
    "1. **Prepare the new representation**: Create the new SimClusters representation using any necessary updates or changes in the clustering algorithm, similarity measures, or other model parameters. Ensure that this new representation is properly stored and indexed as needed.\n",
    "\n",
    "2. **Update the relevant code and configurations**: Modify the relevant code and configuration files to reference the new SimClusters representation. This may involve updating paths or dataset names to point to the new representation, as well as changing code to use the new clustering method or similarity functions if applicable.\n",
    "\n",
    "3. **Test the new representation**: Before deploying the changes to production, thoroughly test the new SimClusters representation to ensure its effectiveness and stability. This may involve running offline jobs like candidate generation and label candidates, validating the output, as well as testing the new representation in the evaluation environment using evaluation tools like TweetSimilarityEvaluationAdhocApp.\n",
    "\n",
    "4. **Deploy the changes**: Once the new representation has been tested and validated, deploy the changes to production. This may involve creating a zip file, uploading it to the packer, and then scheduling it with Aurora. Be sure to monitor the system to ensure a smooth transition between representations and verify that the new representation is being used in recommendations as expected.\n",
    "\n",
    "5. **Monitor and assess the new representation**: After the new representation has been deployed, continue to monitor its performance and impact on recommendations. Take note of any improvements or issues that arise and be prepared to iterate on the new representation if needed. Always ensure that the results and performance metrics align with the system's goals and objectives. \n",
    "\n",
    "-> **Question**: How much do I get boosted within my cluster?\n",
    "\n",
    "**Answer**: It's not possible to determine the exact amount your content is boosted within your cluster in the SimClusters representation without specific data about your content and its engagement metrics. However, a combination of factors, such as the favorite score and follow score, alongside other engagement signals and SimCluster calculations, influence the boosting of content. \n",
    "\n",
    "-> **Question**: How does Heavy ranker work. what are it’s main inputs?\n",
    "\n",
    "**Answer**: The Heavy Ranker is a machine learning model that plays a crucial role in ranking and scoring candidates within the recommendation algorithm. Its primary purpose is to predict the likelihood of a user engaging with a tweet or connecting with another user on the platform.\n",
    "\n",
    "Main inputs to the Heavy Ranker consist of:\n",
    "\n",
    "1. Static Features: These are features that can be computed directly from a tweet at the time it's created, such as whether it has a URL, has cards, has quotes, etc. These features are produced by the Index Ingester as the tweets are generated and stored in the index.\n",
    "\n",
    "2. Real-time Features: These per-tweet features can change after the tweet has been indexed. They mostly consist of social engagements like retweet count, favorite count, reply count, and some spam signals that are computed with later activities. The Signal Ingester, which is part of a Heron topology, processes multiple event streams to collect and compute these real-time features.\n",
    "\n",
    "3. User Table Features: These per-user features are obtained from the User Table Updater that processes a stream written by the user service. This input is used to store sparse real-time user information, which is later propagated to the tweet being scored by looking up the author of the tweet.\n",
    "\n",
    "4. Search Context Features: These features represent the context of the current searcher, like their UI language, their content consumption, and the current time (implied). They are combined with Tweet Data to compute some of the features used in scoring.\n",
    "\n",
    "These inputs are then processed by the Heavy Ranker to score and rank candidates based on their relevance and likelihood of engagement by the user. \n",
    "\n",
    "-> **Question**: How can one influence Heavy ranker?\n",
    "\n",
    "**Answer**: To influence the Heavy Ranker's output or ranking of content, consider the following actions:\n",
    "\n",
    "1. Improve content quality: Create high-quality and engaging content that is relevant, informative, and valuable to users. High-quality content is more likely to receive positive user engagement, which the Heavy Ranker considers when ranking content.\n",
    "\n",
    "2. Increase user engagement: Encourage users to interact with content through likes, retweets, replies, and comments. Higher engagement levels can lead to better ranking in the Heavy Ranker's output.\n",
    "\n",
    "3. Optimize your user profile: A user's reputation, based on factors such as their follower count and follower-to-following ratio, may impact the ranking of their content. Maintain a good reputation by following relevant users, keeping a reasonable follower-to-following ratio and engaging with your followers.\n",
    "\n",
    "4. Enhance content discoverability: Use relevant keywords, hashtags, and mentions in your tweets, making it easier for users to find and engage with your content. This increased discoverability may help improve the ranking of your content by the Heavy Ranker.\n",
    "\n",
    "5. Leverage multimedia content: Experiment with different content formats, such as videos, images, and GIFs, which may capture users' attention and increase engagement, resulting in better ranking by the Heavy Ranker.\n",
    "\n",
    "6. User feedback: Monitor and respond to feedback for your content. Positive feedback may improve your ranking, while negative feedback provides an opportunity to learn and improve.\n",
    "\n",
    "Note that the Heavy Ranker uses a combination of machine learning models and various features to rank the content. While the above actions may help influence the ranking, there are no guarantees as the ranking process is determined by a complex algorithm, which evolves over time. \n",
    "\n",
    "-> **Question**: why threads and long tweets do so well on the platform?\n",
    "\n",
    "**Answer**: Threads and long tweets perform well on the platform for several reasons:\n",
    "\n",
    "1. **More content and context**: Threads and long tweets provide more information and context about a topic, which can make the content more engaging and informative for users. People tend to appreciate a well-structured and detailed explanation of a subject or a story, and threads and long tweets can do that effectively.\n",
    "\n",
    "2. **Increased user engagement**: As threads and long tweets provide more content, they also encourage users to engage with the tweets through replies, retweets, and likes. This increased engagement can lead to better visibility of the content, as the Twitter algorithm considers user engagement when ranking and surfacing tweets.\n",
    "\n",
    "3. **Narrative structure**: Threads enable users to tell stories or present arguments in a step-by-step manner, making the information more accessible and easier to follow. This narrative structure can capture users' attention and encourage them to read through the entire thread and interact with the content.\n",
    "\n",
    "4. **Expanded reach**: When users engage with a thread, their interactions can bring the content to the attention of their followers, helping to expand the reach of the thread. This increased visibility can lead to more interactions and higher performance for the threaded tweets.\n",
    "\n",
    "5. **Higher content quality**: Generally, threads and long tweets require more thought and effort to create, which may lead to higher quality content. Users are more likely to appreciate and interact with high-quality, well-reasoned content, further improving the performance of these tweets within the platform.\n",
    "\n",
    "Overall, threads and long tweets perform well on Twitter because they encourage user engagement and provide a richer, more informative experience that users find valuable. \n",
    "\n",
    "-> **Question**: Are thread and long tweet creators building a following that reacts to only threads?\n",
    "\n",
    "**Answer**: Based on the provided code and context, there isn't enough information to conclude if the creators of threads and long tweets primarily build a following that engages with only thread-based content. The code provided is focused on Twitter's recommendation and ranking algorithms, as well as infrastructure components like Kafka, partitions, and the Follow Recommendations Service (FRS). To answer your question, data analysis of user engagement and results of specific edge cases would be required. \n",
    "\n",
    "-> **Question**: Do you need to follow different strategies to get most followers vs to get most likes and bookmarks per tweet?\n",
    "\n",
    "**Answer**: Yes, different strategies need to be followed to maximize the number of followers compared to maximizing likes and bookmarks per tweet. While there may be some overlap in the approaches, they target different aspects of user engagement.\n",
    "\n",
    "Maximizing followers: The primary focus is on growing your audience on the platform. Strategies include:\n",
    "\n",
    "1. Consistently sharing high-quality content related to your niche or industry.\n",
    "2. Engaging with others on the platform by replying, retweeting, and mentioning other users.\n",
    "3. Using relevant hashtags and participating in trending conversations.\n",
    "4. Collaborating with influencers and other users with a large following.\n",
    "5. Posting at optimal times when your target audience is most active.\n",
    "6. Optimizing your profile by using a clear profile picture, catchy bio, and relevant links.\n",
    "\n",
    "Maximizing likes and bookmarks per tweet: The focus is on creating content that resonates with your existing audience and encourages engagement. Strategies include:\n",
    "\n",
    "1. Crafting engaging and well-written tweets that encourage users to like or save them.\n",
    "2. Incorporating visually appealing elements, such as images, GIFs, or videos, that capture attention.\n",
    "3. Asking questions, sharing opinions, or sparking conversations that encourage users to engage with your tweets.\n",
    "4. Using analytics to understand the type of content that resonates with your audience and tailoring your tweets accordingly.\n",
    "5. Posting a mix of educational, entertaining, and promotional content to maintain variety and interest.\n",
    "6. Timing your tweets strategically to maximize engagement, likes, and bookmarks per tweet.\n",
    "\n",
    "Both strategies can overlap, and you may need to adapt your approach by understanding your target audience's preferences and analyzing your account's performance. However, it's essential to recognize that maximizing followers and maximizing likes and bookmarks per tweet have different focuses and require specific strategies. \n",
    "\n",
    "-> **Question**: Content meta data and how it impacts virality (e.g. ALT in images).\n",
    "\n",
    "**Answer**: There is no direct information in the provided context about how content metadata, such as ALT text in images, impacts the virality of a tweet or post. However, it's worth noting that including ALT text can improve the accessibility of your content for users who rely on screen readers, which may lead to increased engagement for a broader audience. Additionally, metadata can be used in search engine optimization, which might improve the visibility of the content, but the context provided does not mention any specific correlation with virality. \n",
    "\n",
    "-> **Question**: What are some unexpected fingerprints for spam factors?\n",
    "\n",
    "**Answer**: In the provided context, an unusual indicator of spam factors is when a tweet contains a non-media, non-news link. If the tweet has a link but does not have an image URL, video URL, or news URL, it is considered a potential spam vector, and a threshold for user reputation (tweepCredThreshold) is set to MIN_TWEEPCRED_WITH_LINK.\n",
    "\n",
    "While this rule may not cover all possible unusual spam indicators, it is derived from the specific codebase and logic shared in the context. \n",
    "\n",
    "-> **Question**: Is there any difference between company verified checkmarks and blue verified individual checkmarks?\n",
    "\n",
    "**Answer**: Yes, there is a distinction between the verified checkmarks for companies and blue verified checkmarks for individuals. The code snippet provided mentions \"Blue-verified account boost\" which indicates that there is a separate category for blue verified accounts. Typically, blue verified checkmarks are used to indicate notable individuals, while verified checkmarks are for companies or organizations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
