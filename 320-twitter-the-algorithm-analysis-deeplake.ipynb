{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Twitter the-algorithm source code with LangChain, GPT4 and Deep Lake\n",
    "In this tutorial, we are going to use Langchain + Deep Lake with GPT4 to analyze the code base of the twitter algorithm. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define OpenAI embeddings, Deep Lake multi-modal vector store api and authenticate. For full documentation of Deep Lake please follow [docs](https://docs.activeloop.ai/) and [API reference](https://docs.deeplake.ai/en/latest/).\n",
    "\n",
    "Authenticate into Deep Lake if you want to create your own dataset and publish it. You can get an API key from the [platform](https://app.activeloop.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMERS_CACHE=\"/f/C/cache/huggingface/hub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm as notebook_tqdm\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "os.environ['TRANSFORMERS_CACHE'] = 'F:\\C\\cache\\huggingface\\hub'\n",
    "os.environ['ACTIVELOOP_TOKEN'] = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "model_name = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18288524448871613, -0.870093047618866, -0.32214364409446716, 0.24678434431552887, 0.22796113789081573, -0.2532202899456024, -0.05529440939426422, -0.09580593556165695, -0.7816190719604492, 0.24252286553382874, -0.26906847953796387, 0.4532368779182434, -0.25498417019844055, -0.04351048916578293, -0.035494785755872726, -0.13981185853481293, 0.19648775458335876, -0.032967787235975266, 0.29970303177833557, -0.09401503205299377, -0.18382267653942108, 0.26495715975761414, -0.3790799081325531, 0.3223896026611328, -0.2088802456855774, -0.5860763788223267, 0.1507989913225174, -0.2828001081943512, -0.0481543205678463, -0.03162034973502159, -0.2028612196445465, -0.1640581637620926, -0.28339314460754395, 0.21459180116653442, -0.00011060524411732331, -0.15029798448085785, 0.3348582983016968, 0.034457284957170486, 0.029517658054828644, 0.1815199851989746, 0.5139610767364502, 0.3862299919128418, -0.2858322262763977, -0.13628022372722626, -0.14682255685329437, -0.04286551848053932, 0.06980696320533752, -0.345440149307251, 0.0031242931727319956, 0.21952955424785614, 0.19833123683929443, -0.15653854608535767, 0.19081971049308777, 0.1296653151512146, 0.3439304232597351, -0.12268270552158356, -0.11856604367494583, -0.10912589728832245, 0.4032157063484192, -0.2411603480577469, 0.1704675406217575, 0.06654217839241028, -0.066996268928051, -0.217451810836792, 0.07684211432933807, 0.3654032349586487, 0.37202081084251404, 0.08997494727373123, 0.1427871435880661, 0.1658283770084381, -0.08387909829616547, -0.10217008739709854, -0.027996690943837166, -0.30409568548202515, -0.008759046904742718, 0.07290095835924149, 0.3057241141796112, 0.3870856761932373, 0.10382605344057083, 0.272565096616745, 0.04407045990228653, -0.29556140303611755, -0.16874617338180542, 0.1993044763803482, -0.2360394150018692, 0.21177087724208832, -0.12520812451839447, 0.02181990072131157, 0.24103416502475739, -0.12126129120588303, 0.2805330753326416, -0.01400029193609953, -0.01207452267408371, 0.1981247216463089, -0.004780035465955734, -0.2627969980239868, 0.16319528222084045, 0.48395663499832153, -0.036896441131830215, -0.6618964672088623, -0.18040791153907776, -0.03792649134993553, -0.40667444467544556, 0.06899111717939377, 0.14585720002651215, -0.7060120701789856, 0.35476601123809814, 0.6993445158004761, 0.048518791794776917, -0.026496386155486107, -0.20806966722011566, 0.05706257373094559, 0.20814460515975952, -0.03198343142867088, -0.5369137525558472, 0.02789478749036789, 0.10193102806806564, -0.1153842881321907, 0.17023520171642303, -0.08350484073162079, 0.26709336042404175, -0.03339480236172676, 0.06654596328735352, 0.19978174567222595, 0.0632004514336586, 0.4247649312019348, -0.4888102412223816, 0.13692960143089294, 0.044012412428855896, -0.05225596949458122, -0.257275253534317, 0.23567445576190948, -0.2318214625120163, 0.024791501462459564, -0.2780883312225342, -0.280416339635849, 0.003310784697532654, 0.3165048360824585, 0.1551285833120346, 0.04608410969376564, 0.25555068254470825, -0.3611827492713928, -0.14976422488689423, -0.14931190013885498, -0.40048226714134216, -0.19235840439796448, -0.01953079178929329, -0.12728379666805267, -0.21237576007843018, 0.10364347696304321, -0.10671889036893845, -0.1092320904135704, -0.26454949378967285, 0.19384869933128357, 0.3015781342983246, -0.08743742108345032, -0.08586730808019638, 0.21642999351024628, 0.015637356787919998, -0.28355956077575684, -0.06530380994081497, 0.06106504797935486, 0.15473152697086334, -0.2574019730091095, -0.2889835834503174, 0.1388232558965683, -0.18135696649551392, -0.1429067999124527, -0.10149834305047989, -0.3954434096813202, 0.03450993075966835, 0.11005748063325882, -0.010086999274790287, -0.372416615486145, 0.02222384512424469, -0.1256304681301117, -0.21554021537303925, -0.017588790506124496, 0.09634245187044144, -0.5176115036010742, -0.08298645168542862, -0.429314523935318, 0.1713157743215561, -0.13538402318954468, 0.25051599740982056, 0.11707238852977753, 0.2696429491043091, -0.17019201815128326, -0.2017573118209839, -0.06053926423192024, -0.21412082016468048, -0.0833723247051239, -0.3607243597507477, -0.043135423213243484, 0.009407301433384418, 0.09088258445262909, 0.1971154510974884, -0.23184014856815338, 0.14173372089862823, 0.0431009866297245, -0.1143040731549263, 0.30229896306991577, 0.46099886298179626, 0.271775484085083, -0.11225293576717377, 0.07958474010229111, -0.11693491786718369, -0.16900593042373657, -0.24983270466327667, 0.1704384982585907, 0.31210193037986755, -0.09845443814992905, -0.0062124719843268394, -0.03512173518538475, 0.2823021113872528, 0.13302676379680634, 0.19963346421718597, 0.08060943335294724, -0.2509036064147949, 0.18394646048545837, -0.2628244459629059, -0.021614424884319305, -0.37711310386657715, -0.10128609836101532, -0.07877067476511002, 0.400998592376709, 0.07698480784893036, -0.2563410997390747, -0.0588434673845768, 0.004614588804543018, 0.35542166233062744, -0.05631176009774208, 0.307327002286911, 0.24409270286560059, 0.25732335448265076, 0.21620160341262817, 0.4292711913585663, 0.135496124625206, 0.27529028058052063, -0.09324973076581955, 0.12241483479738235, -0.4868379235267639, -0.10393290221691132, 0.17750217020511627, -0.2828076481819153, 0.38999199867248535, 0.30278488993644714, -0.24469441175460815, -0.10662533342838287, 0.03606874495744705, -0.257238507270813, 0.1750735342502594, 0.2845606207847595, -0.2853158414363861, 0.08999718725681305, 0.21977859735488892, 0.005670156329870224, -0.04671601951122284, -0.398052841424942, 0.2262752801179886, 0.2439633160829544, -0.08341647684574127, 0.0624614842236042, 0.23165825009346008, 0.28600621223449707, 0.09512042254209518, 0.1507778763771057, 0.03713779151439667, -0.15355589985847473, 0.13937897980213165, -0.040200065821409225, 0.13723182678222656, 0.09581778198480606, -0.10467129200696945, 0.3116273581981659, 0.09699257463216782, -0.08382372558116913, -0.3568764626979828, -0.3216068148612976, -0.10816989839076996, -0.19071251153945923, -0.21378573775291443, -0.10273617506027222, 0.04089978337287903, -0.0382133312523365, -0.23338758945465088, -0.16593077778816223, 0.2004435658454895, -0.10433725267648697, 0.28338301181793213, -0.13523122668266296, -0.04246598109602928, 0.11443367600440979, 0.053723711520433426, -0.25006231665611267, 0.081467404961586, 0.5958715677261353, 0.36625945568084717, 0.12291301786899567, -0.10089338570833206, -0.1477404236793518, -0.48448646068573, -0.029696499928832054, 0.29903319478034973, -0.22554230690002441, -0.34349843859672546, -0.012961295433342457, 0.18564018607139587, -0.14227014780044556, 0.0018086464842781425, -0.35438618063926697, 0.11825311928987503, 0.06959488242864609, -0.3817294239997864, 0.31371936202049255, 0.22654666006565094, -0.11910682171583176, 0.13717226684093475, 0.026405716314911842, -0.21792787313461304, 0.04501866176724434, -0.204340860247612, -0.0031283048447221518, -0.015143618918955326, -0.08277618139982224, -0.1095597967505455, -0.24196095764636993, -0.030197950080037117, -0.01825987733900547, 0.270335853099823, 0.07532310485839844, -0.0024651032872498035, 0.4433429539203644, 0.04711220785975456, -0.3690020740032196, -0.004150071647018194, 0.06694632768630981, 0.06820466369390488, 0.20736928284168243, 0.12027358263731003, -0.08488064259290695, -0.1778004914522171, -0.14343513548374176, -0.17132648825645447, -0.09137436002492905, -0.5460070967674255, -0.2283375859260559, 0.13616029918193817, -0.2397475242614746, -0.07343069463968277, 0.09051513671875, -0.07391780614852905, 0.4503461420536041, -0.3372959494590759, 0.0034462723415344954, -0.2785080671310425, -0.07144761085510254, 0.1994124948978424, 0.08103808760643005, -0.22791171073913574, 0.1611681878566742, -0.25900065898895264, 0.3222724199295044, 0.06828004866838455, 0.16664913296699524, 0.190788134932518, -0.1542699933052063, 0.25609108805656433, 0.029838552698493004, 0.08604788780212402, 0.2936578094959259, 0.29611936211586, -0.26727521419525146, 0.27131885290145874, 0.15878944098949432, -0.1894889771938324, 0.03388197720050812, -0.12677301466464996, 0.12097424268722534, -0.06697292625904083, 0.037808921188116074, -0.17941762506961823, 0.15743961930274963, -0.19980041682720184, -0.0978623777627945, -0.20874780416488647, 0.08445591479539871, -0.10750237852334976, -0.2704428732395172, 0.30553656816482544, -0.22248338162899017, -0.246114119887352, 0.6249141097068787, 0.010667616501450539, 0.08595742285251617, -0.19161741435527802, -0.0796784907579422, -0.10899488627910614, 0.09424605965614319, 0.11702685803174973, 0.006508237682282925, 0.5749725699424744, 0.2467333823442459, 0.09376237541437149, 0.02386075258255005, 0.009365961886942387, -0.14395558834075928, 0.15049304068088531, -0.10724402964115143, -0.485634982585907, 0.19377538561820984, 0.9957025051116943, -0.5260581970214844, 0.2577170431613922, -0.4255217909812927, -0.05347251892089844, 0.0367053747177124, 0.30991142988204956, -0.03733132779598236, -0.030273765325546265, -0.2618483901023865, 0.3116466999053955, 0.14496251940727234, 0.39302846789360046, 0.11298467963933945, 0.14418986439704895, 0.3232109546661377, -0.2925822138786316, 0.024542970582842827, 0.18947985768318176, 0.4178309142589569, -0.17471753060817719, -0.1617388278245926, 0.16534437239170074, 0.12452149391174316, -0.45426467061042786, 0.025415826588869095, -0.03704383969306946, 0.15643924474716187, 0.22910065948963165, -0.2905738353729248, 0.2255338728427887, 0.2622338533401489, 0.032204948365688324, 0.37248674035072327, -0.47412002086639404, 0.18425874412059784, 0.4933679401874542, -0.17837104201316833, -0.23366647958755493, 0.04493759945034981, -0.11559896916151047, -0.36736419796943665, 0.48963063955307007, 0.015990350395441055, -0.13021767139434814, 0.462617427110672, 0.9765810966491699, 0.15501388907432556, 0.3201058804988861, 0.1806931346654892, 1.2180229425430298, -0.030863014981150627, -0.09636420011520386, 0.07586048543453217, -0.23582755029201508, -0.014434898272156715, -0.4620566964149475, -0.12208744883537292, -0.30824044346809387, 0.15943336486816406, 0.04187518730759621, -0.2882928252220154, 0.24249526858329773, 0.7318176627159119, -0.2676970362663269, -0.14495588839054108, -0.016470100730657578, 0.12859012186527252, 0.3046731650829315, -0.1521015167236328, 0.3158031404018402, 0.15173687040805817, -0.0131454486399889, 0.2323479950428009, 0.11734200268983841, 0.08890626579523087, 0.07546074688434601, 0.06033864989876747, -0.43238943815231323, 0.02740299142897129, 0.19364699721336365, -0.05500895529985428, -0.031232235953211784, 0.10716339200735092, 0.5655713677406311, -0.4674423336982727, 0.11437927186489105, 0.293185293674469, 0.24609427154064178, -0.09183192998170853, 0.04767574369907379, 0.12305651605129242, 0.12091867625713348, -0.17816267907619476, -0.13040386140346527, 0.12095042318105698, -0.2259032130241394, -0.11886996030807495, -0.24391576647758484, 0.48677536845207214, -0.2624771296977997, -0.2851698100566864, -0.21848466992378235, 0.21575523912906647, -0.03773989528417587, 0.0526229590177536, 0.040335483849048615, -0.1150798499584198, -0.1828511655330658, 0.06819837540388107, 0.16015459597110748, 0.18163907527923584, 0.026178210973739624, 0.18132415413856506, 0.13678787648677826, -0.013705357909202576, -0.2601572573184967, 0.09763608127832413, -0.19408732652664185, 0.36910131573677063, -0.08999712765216827, 0.0037942214403301477, -0.29837045073509216, -0.18944650888442993, -0.022639932110905647, -0.608811616897583, -0.09267909079790115, 0.24897171556949615, 0.0375077947974205, -0.3983883559703827, 0.46121007204055786, -0.17976747453212738, 0.021899284794926643, 0.3990801274776459, -0.099085733294487, -0.051693517714738846, -0.32682910561561584, 0.0680493414402008, -0.1488390564918518, -0.033366914838552475, 0.07234354317188263, 0.30440521240234375, 0.024110350757837296, -0.21695464849472046, -0.39381882548332214, 0.024845706298947334, -0.1605309098958969, 0.27427324652671814, 0.3824540674686432, -0.26368948817253113, -0.5133586525917053, -0.06234415993094444, 0.37856414914131165, 0.0722092017531395, 0.07215991616249084, -0.244630366563797, -0.09346220642328262, 0.12470002472400665, -0.030629195272922516, 0.0833689421415329, -0.4943608343601227, 0.12951001524925232, -0.350123792886734, 0.14108368754386902, -0.08517764508724213, -0.16915152966976166, 0.2621079385280609, 0.21091751754283905, 0.294772207736969, -0.068622887134552, -0.1113661602139473, -0.05871211364865303, -0.04492625966668129, -0.059723131358623505, 0.058017756789922714, 0.04235205799341202, 0.08983064442873001, -0.20421363413333893, 0.06515045464038849, 0.13409224152565002, 0.12919290363788605, 0.003525759791955352, 0.15669363737106323, 0.35499247908592224, -0.06957679241895676, -0.0554204098880291, -0.24924735724925995, 0.31559857726097107, -0.13048143684864044, -0.14653711020946503, 0.19948925077915192, 0.20392638444900513, -0.3129054605960846, -0.18329602479934692, 0.11343609541654587, 0.20913903415203094, 0.19202007353305817, 0.10757029056549072, -0.014807702042162418, -0.04117736220359802, 0.07937083393335342, 0.2126649171113968, 0.2731233835220337, -0.11909671127796173, 0.13999401032924652, 0.40505388379096985, 0.1632540374994278, -0.07967817783355713, 0.271344929933548, 0.07372202724218369, -0.10764457285404205, 0.5060548782348633, 0.10181152820587158, 0.12356752157211304, -0.14844189584255219, -0.022387366741895676, 0.6511382460594177, -0.10655178129673004, -0.21514910459518433, 0.35826849937438965, 0.23596981167793274, -0.16205132007598877, 0.2519369125366211, -0.12985903024673462, 0.07184285670518875, -0.1695466786623001, 0.07072921842336655, 0.18272395431995392, -0.025170914828777313, -0.022482991218566895, 0.0843610092997551, -0.35763978958129883, 0.0689907893538475, 0.06983229517936707, 0.050648633390665054, -0.050652820616960526, 0.14713996648788452, -0.02630290761590004, 0.2276092767715454, 0.11140228062868118, 0.14877550303936005, 0.04537513852119446, 0.35436320304870605, 0.08477017283439636, -0.012802197597920895, -0.03155714273452759, 0.10182451456785202, -0.007149612996727228, -0.03388993442058563, 0.09116147458553314, 0.008847491815686226, 0.07132115960121155, 0.037562526762485504, 0.04057801887392998, -0.16498419642448425, 0.06734118610620499, -0.03731203079223633, 0.1445985734462738, -0.06468073278665543, 0.28945350646972656, 0.13425984978675842, -0.311438649892807, 0.049539316445589066, 0.09104862809181213, -0.07047723978757858, 0.07523144781589508, 0.0285160094499588, -0.3021414875984192, -0.3363812565803528, -0.2539176344871521, -0.03089810349047184, 0.05147749185562134, 0.028698040172457695, 0.28304675221443176, 0.0031854682601988316, -0.043812282383441925, 0.041163839399814606, 0.09976822882890701, 0.3419240713119507, 0.30076274275779724, 0.045437298715114594, 0.0768909752368927, -0.18950039148330688, -0.6164520978927612, -0.34143054485321045, 0.30694445967674255, -0.03204319253563881, -0.18682549893856049, -0.025692401453852654, -0.03775913640856743, 0.43238067626953125, 0.02621944062411785, -0.15416769683361053, 0.7687423825263977, -0.5003363490104675, 0.13005907833576202, -0.22802290320396423, -0.09101766347885132, -0.02424861676990986, -0.046584997326135635, 0.14560098946094513, 0.020934810861945152, 0.3479430079460144, 0.2592150866985321, 0.28476715087890625, -0.3972102105617523, 0.06687742471694946, -0.22860455513000488, 0.3165472149848938, -0.16821743547916412, 0.011149578727781773, 0.0703321322798729, -0.36679619550704956, 0.09645447880029678, 0.044963542371988297, -0.20856793224811554, -0.1397121697664261, -0.17380858957767487, 0.23943428695201874, -0.04810687154531479, 0.053151629865169525, 0.08135805279016495, 0.2244350016117096, 0.3586050868034363, 0.32417696714401245, 0.4629010260105133, -0.18453647196292877, 0.14923149347305298, 0.15915071964263916, -0.33652621507644653, -0.29086923599243164, 0.14966025948524475, 0.028414927423000336, -0.27077168226242065, -0.22271986305713654, -0.08535155653953552, 0.1608213633298874, -0.11170034855604172, -0.12944860756397247, 0.1723523885011673, -0.2136353999376297, 0.3901273012161255, -0.046780914068222046, -0.1926511526107788, -0.020144006237387657, 0.22474858164787292, -0.1840687245130539, -0.09094201028347015, -0.26039284467697144, 0.3976938724517822, -0.03835907205939293, -0.16920062899589539, 0.2732034921646118, 0.20517800748348236, 0.14729522168636322, -0.07781987637281418, -0.10910643637180328]\n"
     ]
    }
   ],
   "source": [
    "text = ['seaweed', 'pickles', 'cabbage', 'kimchi']\n",
    "\n",
    "doc_result = embeddings.embed_documents(text)\n",
    "\n",
    "query = \"leafs\"\n",
    "query_result = embeddings.embed_query(query)\n",
    "\n",
    "\n",
    "\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Index the code base (optional)\n",
    "You can directly skip this part and directly jump into using already indexed dataset. To begin with, first we will clone the repository, then parse and chunk the code base and use OpenAI indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/flet-dev/flet \"../sources-repositories\" # replace any repository of your choice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all files inside the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "\"\"\"\n",
    "Walk through the given root directory and load each file's content using TextLoader.\n",
    "\n",
    "Parameters:\n",
    "    root_dir (str): The root directory to start the search from.\n",
    "\n",
    "Returns:\n",
    "    list: A list of documents loaded from the given directory.\n",
    "\"\"\"\n",
    "\n",
    "root_dir = '../sources-repositories/langchain'  # Declare root directory variable\n",
    "docs = []  # Create empty list for documents\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):  # Walk through directory tree using os.walk()\n",
    "    \"\"\" walk() explanation:\n",
    "        On each step of the walk, os.walk() produces a tuple containing three values - the path to the\n",
    "        directory being visited (dirpath), a list of the names of the subdirectories within dirpath (dirnames),\n",
    "        and a list of the names of the files within dirpath (filenames). \"\"\"\n",
    "\n",
    "    for file in filenames:  # Loop through each file in the current directory\n",
    "        try: \n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')  # Use TextLoader to load and split each file's content\n",
    "            # docs.extend(loader.load_and_split())  # Append each document to the list\n",
    "            docs.extend(loader.load()) # just load, don't split\n",
    "        except Exception as e:  # Handle any exceptions that occur during loading and splitting\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs) # number of processed document pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Token Length in Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 4\n",
      "Avg: 496\n",
      "Max: 1036\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_counts = [tiktoken_len(doc.page_content) for doc in docs]\n",
    "\n",
    "print(f\"\"\"Min: {min(token_counts)}\n",
    "Avg: {int(sum(token_counts) / len(token_counts))}\n",
    "Max: {max(token_counts)}\"\"\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set style and color palette for the plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "# create histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(token_counts, kde=False, bins=50)\n",
    "\n",
    "# customize the plot info\n",
    "plt.title(\"Token Counts Histogram\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, chunk the files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Chunking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,  # number of tokens overlap between chunks\n",
    "    length_function=tiktoken_len,\n",
    "    separators=['\\n\\n', '\\n', ' ', '']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='\"\"\"Utilities for formatting strings.\"\"\"\\nfrom string import Formatter\\nfrom typing import Any, Mapping, Sequence, Union\\n\\n\\nclass StrictFormatter(Formatter):\\n    \"\"\"A subclass of formatter that checks for extra keys.\"\"\"\\n\\n    def check_unused_args(\\n        self,\\n        used_args: Sequence[Union[int, str]],\\n        args: Sequence,\\n        kwargs: Mapping[str, Any],\\n    ) -> None:\\n        \"\"\"Check to see if extra parameters are passed.\"\"\"\\n        extra = set(kwargs).difference(used_args)\\n        if extra:\\n            raise KeyError(extra)\\n\\n    def vformat(\\n        self, format_string: str, args: Sequence, kwargs: Mapping[str, Any]\\n    ) -> str:\\n        \"\"\"Check that no arguments are provided.\"\"\"\\n        if len(args) > 0:\\n            raise ValueError(\\n                \"No arguments should be provided, \"\\n                \"everything should be passed as keyword arguments.\"\\n            )\\n        return super().vformat(format_string, args, kwargs)\\n\\n\\nformatter = StrictFormatter()' metadata={'source': '../dev/langchain/langchain\\\\formatting.py'}\n"
     ]
    }
   ],
   "source": [
    "chunks = text_splitter.split_text(docs[5].page_content)\n",
    "len(chunks)\n",
    "print(docs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tiktoken_len(chunks[\u001b[39m4\u001b[39;49m])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tiktoken_len(chunks[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763c2e397a70463bb792163198240acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hashlib\n",
    "m = hashlib.md5()  # this will convert URL into unique ID\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.docstore.document import Document\n",
    "documents = []\n",
    "\n",
    "for doc in tqdm(docs):\n",
    "    url = doc.metadata['source'].replace('../sources-repositories/langchain\\\\', 'https://github.com/hwchase17/langchain/tree/master/langchain/')\n",
    "    m.update(url.encode('utf-8'))\n",
    "    uid = m.hexdigest()[:12]\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        documents.append(\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    'id': f'{uid}-{i}',\n",
    "                    'source': url\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "            # {'text': chunk})\n",
    "        # documents.append({\n",
    "        #     'id': f'{uid}-{i}',\n",
    "        #     'text': chunk,\n",
    "        #     'source': url\n",
    "        # })\n",
    "        # documents.extend(f\"id={uid}-{i}\")\n",
    "        # documents.extend('text={chunk}')\n",
    "        # documents.extend('source={url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1352"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original chunking method\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitterr = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitterr.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='\"\"\"Beta Feature: base interface for cache.\"\"\"\\nimport json\\nfrom abc import ABC, abstractmethod\\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\\n\\nfrom sqlalchemy import Column, Integer, String, create_engine, select\\nfrom sqlalchemy.engine.base import Engine\\nfrom sqlalchemy.orm import Session\\n\\ntry:\\n    from sqlalchemy.orm import declarative_base\\nexcept ImportError:\\n    from sqlalchemy.ext.declarative import declarative_base\\n\\nfrom langchain.schema import Generation\\n\\nRETURN_VAL_TYPE = List[Generation]\\n\\n\\nclass BaseCache(ABC):\\n    \"\"\"Base interface for cache.\"\"\"\\n\\n    @abstractmethod\\n    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\\n        \"\"\"Look up based on prompt and llm_string.\"\"\"\\n\\n    @abstractmethod\\n    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\\n        \"\"\"Update cache based on prompt and llm_string.\"\"\"\\n\\n\\nclass InMemoryCache(BaseCache):\\n    \"\"\"Cache that stores things in memory.\"\"\"' metadata={'source': '../dev/langchain/langchain\\\\cache.py'}\n",
      "<class 'langchain.schema.Document'>\n",
      "page_content='\"\"\"Beta Feature: base interface for cache.\"\"\"\\nimport json\\nfrom abc import ABC, abstractmethod\\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\\n\\nfrom sqlalchemy import Column, Integer, String, create_engine, select\\nfrom sqlalchemy.engine.base import Engine\\nfrom sqlalchemy.orm import Session\\n\\ntry:\\n    from sqlalchemy.orm import declarative_base\\nexcept ImportError:\\n    from sqlalchemy.ext.declarative import declarative_base\\n\\nfrom langchain.schema import Generation\\n\\nRETURN_VAL_TYPE = List[Generation]\\n\\n\\nclass BaseCache(ABC):\\n    \"\"\"Base interface for cache.\"\"\"\\n\\n    @abstractmethod\\n    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\\n        \"\"\"Look up based on prompt and llm_string.\"\"\"\\n\\n    @abstractmethod\\n    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\\n        \"\"\"Update cache based on prompt and llm_string.\"\"\"\\n\\n\\nclass InMemoryCache(BaseCache):\\n    \"\"\"Cache that stores things in memory.\"\"\"\\n\\n    def __init__(self) -> None:\\n        \"\"\"Initialize with empty cache.\"\"\"\\n        self._cache: Dict[Tuple[str, str], RETURN_VAL_TYPE] = {}\\n\\n    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\\n        \"\"\"Look up based on prompt and llm_string.\"\"\"\\n        return self._cache.get((prompt, llm_string), None)\\n\\n    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\\n        \"\"\"Update cache based on prompt and llm_string.\"\"\"\\n        self._cache[(prompt, llm_string)] = return_val\\n\\n\\nBase = declarative_base()\\n\\n\\nclass FullLLMCache(Base):  # type: ignore\\n    \"\"\"SQLite table for full LLM Cache (all generations).\"\"\"' metadata={'id': '0f413d847e74-0', 'source': 'https://github.com/hwchase17/langchain/tree/master/langchain/cache.py'}\n",
      "<class 'langchain.schema.Document'>\n"
     ]
    }
   ],
   "source": [
    "# Compare to see if the datatypes created by CharacterTextSplitter and the new method are langchain schemas.\n",
    "print(texts[0])\n",
    "print(type(texts[0]))\n",
    "print(documents[0])\n",
    "print(type(documents[0]))\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the indexing. This will take about ~4 mins to compute embeddings and upload to Activeloop. You can then publish the dataset to be public."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"langchain_v2\"\n",
    "\n",
    "content_source = documents\n",
    "# content_source = text   # Old chunking method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local vector store\n",
    "\n",
    "Stored in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem://langchain_v2 loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "Evaluating ingest: 0%|          | 0/2 [00:00<?"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c75c6b670e4a5abe5005c58fc87db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "Evaluating ingest: 50%|     | 1/2 [00:21<00:21"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3596d967698442ca8c805ad437fa9c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|| 2/2 [00:32<00:00\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='mem://langchain_v2', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape      dtype  compression\n",
      "  -------   -------    -------    -------  ------- \n",
      " embedding  generic  (1352, 768)  float32   None   \n",
      "    ids      text     (1352, 1)     str     None   \n",
      " metadata    json     (1352, 1)     str     None   \n",
      "   text      text     (1352, 1)     str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import deeplake\n",
    "db = DeepLake.from_documents(content_source, embeddings, dataset_path=f\"mem://{database_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote storage\n",
    "\n",
    "Uses Activeloop API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ACTIVELOOP_TOKEN'] = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "db = DeepLake.from_documents(content_source, embeddings, dataset_path=f\"hub://deadbranches/{database_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem://langchain_v2 loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): spire.bugout.dev:443\n",
      "DEBUG:urllib3.connectionpool:https://spire.bugout.dev:443 \"POST /humbug/reports HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(dataset_path=f\"mem://{database_name}\", read_only=True, embedding_function=embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DeepLake(dataset_path=f\"hub://deadbranches/{database_name}\", read_only=True, embedding_function=embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Question Answering on Twitter algorithm codebase\n",
    "First load the dataset, construct the retriever, then construct the Conversational Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'dot'\n",
    "retriever.search_kwargs['fetch_k'] = 100\n",
    "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "retriever.search_kwargs['k'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce68a90173da48328db3f25a3a2499f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DeepLake' object has no attribute 'rerank'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[185], line 14\u001b[0m\n\u001b[0;32m      4\u001b[0m results \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39msimilarity_search(query, distance_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdot\u001b[39m\u001b[39m'\u001b[39m, k\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# # print(\"class:\", type(results).__name__)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# for result in results:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m#     print(f\"Source:  {result.metadata['source']} \")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m#     print(page_content)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#     print(\"\\n\\n\")\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m reranked_results \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39;49mrerank(\n\u001b[0;32m     15\u001b[0m     query\u001b[39m=\u001b[39mquery,\n\u001b[0;32m     16\u001b[0m     documents\u001b[39m=\u001b[39mresults,\n\u001b[0;32m     17\u001b[0m     distance_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdot\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m     k\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[0;32m     19\u001b[0m     maximal_marginal_relevance\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m  \u001b[39m# set the parameter here\u001b[39;00m\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mclass:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m(reranked_results)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DeepLake' object has no attribute 'rerank'"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "How do I load a LLaMA model for inference that has been quantized using GPTQ's 4bit 128 group size quantization?\n",
    "\"\"\"\n",
    "results = db.similarity_search(query, distance_metric='dot', k=4)\n",
    "\n",
    "# print(\"class:\", type(results).__name__)\n",
    "for result in results:\n",
    "    print(f\"Source:  {result.metadata['source']} \")\n",
    "    print(\"\\nContent:  \")\n",
    "    page_content = json.dumps(result.page_content).replace('\\\\n', '\\n').replace('\\\\\"', '\"')\n",
    "    print(page_content)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "reranked_results = db.rerank(\n",
    "    query=query,\n",
    "    documents=results,\n",
    "    distance_metric='dot',\n",
    "    k=4,\n",
    "    maximal_marginal_relevance=0.5  # set the parameter here\n",
    ")\n",
    "\n",
    "print(\"class:\", type(reranked_results).__name__)\n",
    "print(\"[\")\n",
    "for result in reranked_results:\n",
    "    print(\"    {\")\n",
    "    print(f\"        'page_content': {json.dumps(result.page_content)},\")\n",
    "    print(f\"        'metadata': {json.dumps(result.metadata)},\")\n",
    "    print(f\"        'score': {result.score},\")\n",
    "    print(\"    },\")\n",
    "print(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify user defined functions using [Deep Lake filters](https://docs.deeplake.ai/en/latest/deeplake.core.dataset.html#deeplake.core.dataset.Dataset.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(x):\n",
    "    # filter based on source code\n",
    "    # if 'com.google' in x['text'].data()['value']:\n",
    "    #     return False\n",
    "    \n",
    "    # filter based on path e.g. extension\n",
    "    metadata =  x['metadata'].data()['value']\n",
    "    return 'scala' in metadata['source'] or 'py' in metadata['source']\n",
    "\n",
    "### turn on below for custom filtering\n",
    "# retriever.search_kwargs['filter'] = filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "#model = ChatOpenAI(model='gpt-4') # 'gpt-3.5-turbo',\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo') # 'gpt-3.5-turbo',\n",
    "qa = ConversationalRetrievalChain.from_llm(model,retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78407ad8061944abbb6fe41d763e018d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"messages\": [{\"role\": \"system\", \"content\": \"Use the following pieces of context to answer the users question. \\\\nIf you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\\\n----------------\\\\nHourly Parameter Definition\\\\nThe parameter &hourly= accepts the following values. Most weather variables are given as an instantaneous value for the indicated hour. Some variables like precipitation are calculated from the preceding hour as an average or sum.\\\\n\\\\nHourly Parameter Definition\\\\nThe parameter &hourly= accepts the following values. Most weather variables are given as an instantaneous value for the indicated hour. Some variables like precipitation are calculated from the preceding hour as an average or sum.\\\\n\\\\ndef _default_scripting_text_mapping(\\\\n    dim: int,\\\\n    vector_field: str = \\\\\"vector_field\\\\\",\\\\n) -> Dict:\\\\n    \\\\\"\\\\\"\\\\\"For Painless Scripting or Script Scoring,the default mapping to create index.\\\\\"\\\\\"\\\\\"\\\\n    return {\\\\n        \\\\\"mappings\\\\\": {\\\\n            \\\\\"properties\\\\\": {\\\\n                vector_field: {\\\\\"type\\\\\": \\\\\"knn_vector\\\\\", \\\\\"dimension\\\\\": dim},\\\\n            }\\\\n        }\\\\n    }\\\\n\\\\ndef _default_scripting_text_mapping(\\\\n    dim: int,\\\\n    vector_field: str = \\\\\"vector_field\\\\\",\\\\n) -> Dict:\\\\n    \\\\\"\\\\\"\\\\\"For Painless Scripting or Script Scoring,the default mapping to create index.\\\\\"\\\\\"\\\\\"\\\\n    return {\\\\n        \\\\\"mappings\\\\\": {\\\\n            \\\\\"properties\\\\\": {\\\\n                vector_field: {\\\\\"type\\\\\": \\\\\"knn_vector\\\\\", \\\\\"dimension\\\\\": dim},\\\\n            }\\\\n        }\\\\n    }\\\\n\\\\ndef _default_script_query(\\\\n    query_vector: List[float],\\\\n    space_type: str = \\\\\"l2\\\\\",\\\\n    pre_filter: Dict = MATCH_ALL_QUERY,\\\\n    vector_field: str = \\\\\"vector_field\\\\\",\\\\n) -> Dict:\\\\n    \\\\\"\\\\\"\\\\\"For Script Scoring Search, this is the default query.\\\\\"\\\\\"\\\\\"\\\\n    return {\\\\n        \\\\\"query\\\\\": {\\\\n            \\\\\"script_score\\\\\": {\\\\n                \\\\\"query\\\\\": pre_filter,\\\\n                \\\\\"script\\\\\": {\\\\n                    \\\\\"source\\\\\": \\\\\"knn_score\\\\\",\\\\n                    \\\\\"lang\\\\\": \\\\\"knn\\\\\",\\\\n                    \\\\\"params\\\\\": {\\\\n                        \\\\\"field\\\\\": vector_field,\\\\n                        \\\\\"query_value\\\\\": query_vector,\\\\n                        \\\\\"space_type\\\\\": space_type,\\\\n                    },\\\\n                },\\\\n            }\\\\n        }\\\\n    }\\\\n\\\\ndef _default_script_query(\\\\n    query_vector: List[float],\\\\n    space_type: str = \\\\\"l2\\\\\",\\\\n    pre_filter: Dict = MATCH_ALL_QUERY,\\\\n    vector_field: str = \\\\\"vector_field\\\\\",\\\\n) -> Dict:\\\\n    \\\\\"\\\\\"\\\\\"For Script Scoring Search, this is the default query.\\\\\"\\\\\"\\\\\"\\\\n    return {\\\\n        \\\\\"query\\\\\": {\\\\n            \\\\\"script_score\\\\\": {\\\\n                \\\\\"query\\\\\": pre_filter,\\\\n                \\\\\"script\\\\\": {\\\\n                    \\\\\"source\\\\\": \\\\\"knn_score\\\\\",\\\\n                    \\\\\"lang\\\\\": \\\\\"knn\\\\\",\\\\n                    \\\\\"params\\\\\": {\\\\n                        \\\\\"field\\\\\": vector_field,\\\\n                        \\\\\"query_value\\\\\": query_vector,\\\\n                        \\\\\"space_type\\\\\": space_type,\\\\n                    },\\\\n                },\\\\n            }\\\\n        }\\\\n    }\\\\n\\\\ndef similarity_search_with_score(\\\\n        self, query: str, k: int = 4\\\\n    ) -> List[Tuple[Document, float]]:\\\\n        \\\\\"\\\\\"\\\\\"Return docs most similar to query.\\\\n\\\\n        Args:\\\\n            query: Text to look up documents similar to.\\\\n            k: Number of Documents to return. Defaults to 4.\\\\n\\\\n        Returns:\\\\n            List of Documents most similar to the query and score for each\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        try:\\\\n            from redis.commands.search.query import Query\\\\n        except ImportError:\\\\n            raise ValueError(\\\\n                \\\\\"Could not import redis python package. \\\\\"\\\\n                \\\\\"Please install it with `pip install redis`.\\\\\"\\\\n            )\\\\n\\\\n        # Creates embedding vector from user query\\\\n        embedding = self.embedding_function(query)\\\\n\\\\ndef similarity_search_with_score(\\\\n        self, query: str, k: int = 4\\\\n    ) -> List[Tuple[Document, float]]:\\\\n        \\\\\"\\\\\"\\\\\"Return docs most similar to query.\\\\n\\\\n        Args:\\\\n            query: Text to look up documents similar to.\\\\n            k: Number of Documents to return. Defaults to 4.\\\\n\\\\n        Returns:\\\\n            List of Documents most similar to the query and score for each\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        try:\\\\n            from redis.commands.search.query import Query\\\\n        except ImportError:\\\\n            raise ValueError(\\\\n                \\\\\"Could not import redis python package. \\\\\"\\\\n                \\\\\"Please install it with `pip install redis`.\\\\\"\\\\n            )\\\\n\\\\n        # Creates embedding vector from user query\\\\n        embedding = self.embedding_function(query)\\\\n\\\\nBy default supports Approximate Search.\\\\n        Also supports Script Scoring and Painless Scripting.\\\\n\\\\n        Args:\\\\n            query: Text to look up documents similar to.\\\\n            k: Number of Documents to return. Defaults to 4.\\\\n\\\\n        Returns:\\\\n            List of Documents most similar to the query.\\\\n\\\\n        Optional Args:\\\\n            vector_field: Document field embeddings are stored in. Defaults to\\\\n            \\\\\"vector_field\\\\\".\\\\n\\\\n            text_field: Document field the text of the document is stored in. Defaults\\\\n            to \\\\\"text\\\\\".\\\\n\\\\n            metadata_field: Document field that metadata is stored in. Defaults to\\\\n            \\\\\"metadata\\\\\".\\\\n            Can be set to a special value \\\\\"*\\\\\" to include the entire document.\\\\n\\\\n        Optional Args for Approximate Search:\\\\n            search_type: \\\\\"approximate_search\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            size: number of results the query actually returns; default: 4\\\\n\\\\nBy default supports Approximate Search.\\\\n        Also supports Script Scoring and Painless Scripting.\\\\n\\\\n        Args:\\\\n            query: Text to look up documents similar to.\\\\n            k: Number of Documents to return. Defaults to 4.\\\\n\\\\n        Returns:\\\\n            List of Documents most similar to the query.\\\\n\\\\n        Optional Args:\\\\n            vector_field: Document field embeddings are stored in. Defaults to\\\\n            \\\\\"vector_field\\\\\".\\\\n\\\\n            text_field: Document field the text of the document is stored in. Defaults\\\\n            to \\\\\"text\\\\\".\\\\n\\\\n            metadata_field: Document field that metadata is stored in. Defaults to\\\\n            \\\\\"metadata\\\\\".\\\\n            Can be set to a special value \\\\\"*\\\\\" to include the entire document.\\\\n\\\\n        Optional Args for Approximate Search:\\\\n            search_type: \\\\\"approximate_search\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            size: number of results the query actually returns; default: 4\\\\n\\\\ndef print_text(text: str, color: Optional[str] = None, end: str = \\\\\"\\\\\") -> None:\\\\n    \\\\\"\\\\\"\\\\\"Print text with highlighting and no end characters.\\\\\"\\\\\"\\\\\"\\\\n    if color is None:\\\\n        text_to_print = text\\\\n    else:\\\\n        text_to_print = get_colored_text(text, color)\\\\n    print(text_to_print, end=end)\\\\n\\\\ndef print_text(text: str, color: Optional[str] = None, end: str = \\\\\"\\\\\") -> None:\\\\n    \\\\\"\\\\\"\\\\\"Print text with highlighting and no end characters.\\\\\"\\\\\"\\\\\"\\\\n    if color is None:\\\\n        text_to_print = text\\\\n    else:\\\\n        text_to_print = get_colored_text(text, color)\\\\n    print(text_to_print, end=end)\\\\n\\\\nOptional Args for Script Scoring Search:\\\\n            search_type: \\\\\"script_scoring\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            space_type: \\\\\"l2\\\\\", \\\\\"l1\\\\\", \\\\\"linf\\\\\", \\\\\"cosinesimil\\\\\", \\\\\"innerproduct\\\\\",\\\\n            \\\\\"hammingbit\\\\\"; default: \\\\\"l2\\\\\"\\\\n\\\\n            pre_filter: script_score query to pre-filter documents before identifying\\\\n            nearest neighbors; default: {\\\\\"match_all\\\\\": {}}\\\\n\\\\n        Optional Args for Painless Scripting Search:\\\\n            search_type: \\\\\"painless_scripting\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            space_type: \\\\\"l2Squared\\\\\", \\\\\"l1Norm\\\\\", \\\\\"cosineSimilarity\\\\\"; default: \\\\\"l2Squared\\\\\"\\\\n\\\\nOptional Args for Script Scoring Search:\\\\n            search_type: \\\\\"script_scoring\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            space_type: \\\\\"l2\\\\\", \\\\\"l1\\\\\", \\\\\"linf\\\\\", \\\\\"cosinesimil\\\\\", \\\\\"innerproduct\\\\\",\\\\n            \\\\\"hammingbit\\\\\"; default: \\\\\"l2\\\\\"\\\\n\\\\n            pre_filter: script_score query to pre-filter documents before identifying\\\\n            nearest neighbors; default: {\\\\\"match_all\\\\\": {}}\\\\n\\\\n        Optional Args for Painless Scripting Search:\\\\n            search_type: \\\\\"painless_scripting\\\\\"; default: \\\\\"approximate_search\\\\\"\\\\n\\\\n            space_type: \\\\\"l2Squared\\\\\", \\\\\"l1Norm\\\\\", \\\\\"cosineSimilarity\\\\\"; default: \\\\\"l2Squared\\\\\"\\\\n\\\\nReturns:\\\\n            bool: Whether or not the drop was successful.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        redis_url = get_from_dict_or_env(kwargs, \\\\\"redis_url\\\\\", \\\\\"REDIS_URL\\\\\")\\\\n        try:\\\\n            import redis\\\\n        except ImportError:\\\\n            raise ValueError(\\\\n                \\\\\"Could not import redis python package. \\\\\"\\\\n                \\\\\"Please install it with `pip install redis`.\\\\\"\\\\n            )\\\\n        try:\\\\n            # We need to first remove redis_url from kwargs,\\\\n            # otherwise passing it to Redis will result in an error.\\\\n            kwargs.pop(\\\\\"redis_url\\\\\")\\\\n            client = redis.from_url(url=redis_url, **kwargs)\\\\n        except ValueError as e:\\\\n            raise ValueError(f\\\\\"Your redis connected error: {e}\\\\\")\\\\n        # Check if index exists\\\\n        try:\\\\n            client.ft(index_name).dropindex(delete_documents)\\\\n            logger.info(\\\\\"Drop index\\\\\")\\\\n            return True\\\\n        except:  # noqa: E722\\\\n            # Index not exist\\\\n            return False\\\\n\\\\nReturns:\\\\n            bool: Whether or not the drop was successful.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        redis_url = get_from_dict_or_env(kwargs, \\\\\"redis_url\\\\\", \\\\\"REDIS_URL\\\\\")\\\\n        try:\\\\n            import redis\\\\n        except ImportError:\\\\n            raise ValueError(\\\\n                \\\\\"Could not import redis python package. \\\\\"\\\\n                \\\\\"Please install it with `pip install redis`.\\\\\"\\\\n            )\\\\n        try:\\\\n            # We need to first remove redis_url from kwargs,\\\\n            # otherwise passing it to Redis will result in an error.\\\\n            kwargs.pop(\\\\\"redis_url\\\\\")\\\\n            client = redis.from_url(url=redis_url, **kwargs)\\\\n        except ValueError as e:\\\\n            raise ValueError(f\\\\\"Your redis connected error: {e}\\\\\")\\\\n        # Check if index exists\\\\n        try:\\\\n            client.ft(index_name).dropindex(delete_documents)\\\\n            logger.info(\\\\\"Drop index\\\\\")\\\\n            return True\\\\n        except:  # noqa: E722\\\\n            # Index not exist\\\\n            return False\\\\n\\\\ndef _get_driver(self) -> Union[\\\\\"Chrome\\\\\", \\\\\"Firefox\\\\\"]:\\\\n        \\\\\"\\\\\"\\\\\"Create and return a WebDriver instance based on the specified browser.\\\\n\\\\n        Raises:\\\\n            ValueError: If an invalid browser is specified.\\\\n\\\\n        Returns:\\\\n            Union[Chrome, Firefox]: A WebDriver instance for the specified browser.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        if self.browser.lower() == \\\\\"chrome\\\\\":\\\\n            from selenium.webdriver import Chrome\\\\n            from selenium.webdriver.chrome.options import Options as ChromeOptions\\\\n\\\\ndef _get_driver(self) -> Union[\\\\\"Chrome\\\\\", \\\\\"Firefox\\\\\"]:\\\\n        \\\\\"\\\\\"\\\\\"Create and return a WebDriver instance based on the specified browser.\\\\n\\\\n        Raises:\\\\n            ValueError: If an invalid browser is specified.\\\\n\\\\n        Returns:\\\\n            Union[Chrome, Firefox]: A WebDriver instance for the specified browser.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        if self.browser.lower() == \\\\\"chrome\\\\\":\\\\n            from selenium.webdriver import Chrome\\\\n            from selenium.webdriver.chrome.options import Options as ChromeOptions\\\\n\\\\nelse:\\\\n            toret = \\\\\"No good search result found\\\\\"\\\\n        return toret\\\\n\\\\nelse:\\\\n            toret = \\\\\"No good search result found\\\\\"\\\\n        return toret\"}, {\"role\": \"user\", \"content\": \"How do I load a 4bit quantized LLaMA model into langchain for inference tasks? The model was quantized using GPTQ, and has a group size of 128?\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.7}' message='Post details'\n",
      "DEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "DEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4838 request_id=3111b5c1c9fe6d25c9d28525dc37bd8f response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: How do I load a 4bit quantized LLaMA model into langchain for inference tasks? The model was quantized using GPTQ, and has a group size of 128? \n",
      "\n",
      "**Answer**: I'm sorry, but I am not familiar with the Langchain framework or with the GPTQ quantization method. Without more information, I cannot provide an accurate answer to your question. Can you provide more details or context about what you are trying to do? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"How do I load a 4bit quantized LLaMA model into langchain for inference tasks? The model was quantized using GPTQ, and has a group size of 128?\",\n",
    "] \n",
    "chat_history = []\n",
    "\n",
    "# for question in questions:  \n",
    "#     result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "#     print(result)\n",
    "\n",
    "for question in questions:  \n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> **Question**: What does favCountParams do? \n",
    "\n",
    "**Answer**: `favCountParams` is an optional ThriftLinearFeatureRankingParams instance that represents the parameters related to the \"favorite count\" feature in the ranking process. It is used to control the weight of the favorite count feature while ranking tweets. The favorite count is the number of times a tweet has been marked as a favorite by users, and it is considered an important signal in the ranking of tweets. By using `favCountParams`, the system can adjust the importance of the favorite count while calculating the final ranking score of a tweet. \n",
    "\n",
    "-> **Question**: is it Likes + Bookmarks, or not clear from the code?\n",
    "\n",
    "**Answer**: From the provided code, it is not clear if the favorite count metric is determined by the sum of likes and bookmarks. The favorite count is mentioned in the code, but there is no explicit reference to how it is calculated in terms of likes and bookmarks. \n",
    "\n",
    "-> **Question**: What are the major negative modifiers that lower your linear ranking parameters?\n",
    "\n",
    "**Answer**: In the given code, major negative modifiers that lower the linear ranking parameters are:\n",
    "\n",
    "1. `scoringData.querySpecificScore`: This score adjustment is based on the query-specific information. If its value is negative, it will lower the linear ranking parameters.\n",
    "\n",
    "2. `scoringData.authorSpecificScore`: This score adjustment is based on the author-specific information. If its value is negative, it will also lower the linear ranking parameters.\n",
    "\n",
    "Please note that I cannot provide more information on the exact calculations of these negative modifiers, as the code for their determination is not provided. \n",
    "\n",
    "-> **Question**: How do you get assigned to SimClusters?\n",
    "\n",
    "**Answer**: The assignment to SimClusters occurs through a Metropolis-Hastings sampling-based community detection algorithm that is run on the Producer-Producer similarity graph. This graph is created by computing the cosine similarity scores between the users who follow each producer. The algorithm identifies communities or clusters of Producers with similar followers, and takes a parameter *k* for specifying the number of communities to be detected.\n",
    "\n",
    "After the community detection, different users and content are represented as sparse, interpretable vectors within these identified communities (SimClusters). The resulting SimClusters embeddings can be used for various recommendation tasks. \n",
    "\n",
    "-> **Question**: What is needed to migrate from one SimClusters to another SimClusters?\n",
    "\n",
    "**Answer**: To migrate from one SimClusters representation to another, you can follow these general steps:\n",
    "\n",
    "1. **Prepare the new representation**: Create the new SimClusters representation using any necessary updates or changes in the clustering algorithm, similarity measures, or other model parameters. Ensure that this new representation is properly stored and indexed as needed.\n",
    "\n",
    "2. **Update the relevant code and configurations**: Modify the relevant code and configuration files to reference the new SimClusters representation. This may involve updating paths or dataset names to point to the new representation, as well as changing code to use the new clustering method or similarity functions if applicable.\n",
    "\n",
    "3. **Test the new representation**: Before deploying the changes to production, thoroughly test the new SimClusters representation to ensure its effectiveness and stability. This may involve running offline jobs like candidate generation and label candidates, validating the output, as well as testing the new representation in the evaluation environment using evaluation tools like TweetSimilarityEvaluationAdhocApp.\n",
    "\n",
    "4. **Deploy the changes**: Once the new representation has been tested and validated, deploy the changes to production. This may involve creating a zip file, uploading it to the packer, and then scheduling it with Aurora. Be sure to monitor the system to ensure a smooth transition between representations and verify that the new representation is being used in recommendations as expected.\n",
    "\n",
    "5. **Monitor and assess the new representation**: After the new representation has been deployed, continue to monitor its performance and impact on recommendations. Take note of any improvements or issues that arise and be prepared to iterate on the new representation if needed. Always ensure that the results and performance metrics align with the system's goals and objectives. \n",
    "\n",
    "-> **Question**: How much do I get boosted within my cluster?\n",
    "\n",
    "**Answer**: It's not possible to determine the exact amount your content is boosted within your cluster in the SimClusters representation without specific data about your content and its engagement metrics. However, a combination of factors, such as the favorite score and follow score, alongside other engagement signals and SimCluster calculations, influence the boosting of content. \n",
    "\n",
    "-> **Question**: How does Heavy ranker work. what are its main inputs?\n",
    "\n",
    "**Answer**: The Heavy Ranker is a machine learning model that plays a crucial role in ranking and scoring candidates within the recommendation algorithm. Its primary purpose is to predict the likelihood of a user engaging with a tweet or connecting with another user on the platform.\n",
    "\n",
    "Main inputs to the Heavy Ranker consist of:\n",
    "\n",
    "1. Static Features: These are features that can be computed directly from a tweet at the time it's created, such as whether it has a URL, has cards, has quotes, etc. These features are produced by the Index Ingester as the tweets are generated and stored in the index.\n",
    "\n",
    "2. Real-time Features: These per-tweet features can change after the tweet has been indexed. They mostly consist of social engagements like retweet count, favorite count, reply count, and some spam signals that are computed with later activities. The Signal Ingester, which is part of a Heron topology, processes multiple event streams to collect and compute these real-time features.\n",
    "\n",
    "3. User Table Features: These per-user features are obtained from the User Table Updater that processes a stream written by the user service. This input is used to store sparse real-time user information, which is later propagated to the tweet being scored by looking up the author of the tweet.\n",
    "\n",
    "4. Search Context Features: These features represent the context of the current searcher, like their UI language, their content consumption, and the current time (implied). They are combined with Tweet Data to compute some of the features used in scoring.\n",
    "\n",
    "These inputs are then processed by the Heavy Ranker to score and rank candidates based on their relevance and likelihood of engagement by the user. \n",
    "\n",
    "-> **Question**: How can one influence Heavy ranker?\n",
    "\n",
    "**Answer**: To influence the Heavy Ranker's output or ranking of content, consider the following actions:\n",
    "\n",
    "1. Improve content quality: Create high-quality and engaging content that is relevant, informative, and valuable to users. High-quality content is more likely to receive positive user engagement, which the Heavy Ranker considers when ranking content.\n",
    "\n",
    "2. Increase user engagement: Encourage users to interact with content through likes, retweets, replies, and comments. Higher engagement levels can lead to better ranking in the Heavy Ranker's output.\n",
    "\n",
    "3. Optimize your user profile: A user's reputation, based on factors such as their follower count and follower-to-following ratio, may impact the ranking of their content. Maintain a good reputation by following relevant users, keeping a reasonable follower-to-following ratio and engaging with your followers.\n",
    "\n",
    "4. Enhance content discoverability: Use relevant keywords, hashtags, and mentions in your tweets, making it easier for users to find and engage with your content. This increased discoverability may help improve the ranking of your content by the Heavy Ranker.\n",
    "\n",
    "5. Leverage multimedia content: Experiment with different content formats, such as videos, images, and GIFs, which may capture users' attention and increase engagement, resulting in better ranking by the Heavy Ranker.\n",
    "\n",
    "6. User feedback: Monitor and respond to feedback for your content. Positive feedback may improve your ranking, while negative feedback provides an opportunity to learn and improve.\n",
    "\n",
    "Note that the Heavy Ranker uses a combination of machine learning models and various features to rank the content. While the above actions may help influence the ranking, there are no guarantees as the ranking process is determined by a complex algorithm, which evolves over time. \n",
    "\n",
    "-> **Question**: why threads and long tweets do so well on the platform?\n",
    "\n",
    "**Answer**: Threads and long tweets perform well on the platform for several reasons:\n",
    "\n",
    "1. **More content and context**: Threads and long tweets provide more information and context about a topic, which can make the content more engaging and informative for users. People tend to appreciate a well-structured and detailed explanation of a subject or a story, and threads and long tweets can do that effectively.\n",
    "\n",
    "2. **Increased user engagement**: As threads and long tweets provide more content, they also encourage users to engage with the tweets through replies, retweets, and likes. This increased engagement can lead to better visibility of the content, as the Twitter algorithm considers user engagement when ranking and surfacing tweets.\n",
    "\n",
    "3. **Narrative structure**: Threads enable users to tell stories or present arguments in a step-by-step manner, making the information more accessible and easier to follow. This narrative structure can capture users' attention and encourage them to read through the entire thread and interact with the content.\n",
    "\n",
    "4. **Expanded reach**: When users engage with a thread, their interactions can bring the content to the attention of their followers, helping to expand the reach of the thread. This increased visibility can lead to more interactions and higher performance for the threaded tweets.\n",
    "\n",
    "5. **Higher content quality**: Generally, threads and long tweets require more thought and effort to create, which may lead to higher quality content. Users are more likely to appreciate and interact with high-quality, well-reasoned content, further improving the performance of these tweets within the platform.\n",
    "\n",
    "Overall, threads and long tweets perform well on Twitter because they encourage user engagement and provide a richer, more informative experience that users find valuable. \n",
    "\n",
    "-> **Question**: Are thread and long tweet creators building a following that reacts to only threads?\n",
    "\n",
    "**Answer**: Based on the provided code and context, there isn't enough information to conclude if the creators of threads and long tweets primarily build a following that engages with only thread-based content. The code provided is focused on Twitter's recommendation and ranking algorithms, as well as infrastructure components like Kafka, partitions, and the Follow Recommendations Service (FRS). To answer your question, data analysis of user engagement and results of specific edge cases would be required. \n",
    "\n",
    "-> **Question**: Do you need to follow different strategies to get most followers vs to get most likes and bookmarks per tweet?\n",
    "\n",
    "**Answer**: Yes, different strategies need to be followed to maximize the number of followers compared to maximizing likes and bookmarks per tweet. While there may be some overlap in the approaches, they target different aspects of user engagement.\n",
    "\n",
    "Maximizing followers: The primary focus is on growing your audience on the platform. Strategies include:\n",
    "\n",
    "1. Consistently sharing high-quality content related to your niche or industry.\n",
    "2. Engaging with others on the platform by replying, retweeting, and mentioning other users.\n",
    "3. Using relevant hashtags and participating in trending conversations.\n",
    "4. Collaborating with influencers and other users with a large following.\n",
    "5. Posting at optimal times when your target audience is most active.\n",
    "6. Optimizing your profile by using a clear profile picture, catchy bio, and relevant links.\n",
    "\n",
    "Maximizing likes and bookmarks per tweet: The focus is on creating content that resonates with your existing audience and encourages engagement. Strategies include:\n",
    "\n",
    "1. Crafting engaging and well-written tweets that encourage users to like or save them.\n",
    "2. Incorporating visually appealing elements, such as images, GIFs, or videos, that capture attention.\n",
    "3. Asking questions, sharing opinions, or sparking conversations that encourage users to engage with your tweets.\n",
    "4. Using analytics to understand the type of content that resonates with your audience and tailoring your tweets accordingly.\n",
    "5. Posting a mix of educational, entertaining, and promotional content to maintain variety and interest.\n",
    "6. Timing your tweets strategically to maximize engagement, likes, and bookmarks per tweet.\n",
    "\n",
    "Both strategies can overlap, and you may need to adapt your approach by understanding your target audience's preferences and analyzing your account's performance. However, it's essential to recognize that maximizing followers and maximizing likes and bookmarks per tweet have different focuses and require specific strategies. \n",
    "\n",
    "-> **Question**: Content meta data and how it impacts virality (e.g. ALT in images).\n",
    "\n",
    "**Answer**: There is no direct information in the provided context about how content metadata, such as ALT text in images, impacts the virality of a tweet or post. However, it's worth noting that including ALT text can improve the accessibility of your content for users who rely on screen readers, which may lead to increased engagement for a broader audience. Additionally, metadata can be used in search engine optimization, which might improve the visibility of the content, but the context provided does not mention any specific correlation with virality. \n",
    "\n",
    "-> **Question**: What are some unexpected fingerprints for spam factors?\n",
    "\n",
    "**Answer**: In the provided context, an unusual indicator of spam factors is when a tweet contains a non-media, non-news link. If the tweet has a link but does not have an image URL, video URL, or news URL, it is considered a potential spam vector, and a threshold for user reputation (tweepCredThreshold) is set to MIN_TWEEPCRED_WITH_LINK.\n",
    "\n",
    "While this rule may not cover all possible unusual spam indicators, it is derived from the specific codebase and logic shared in the context. \n",
    "\n",
    "-> **Question**: Is there any difference between company verified checkmarks and blue verified individual checkmarks?\n",
    "\n",
    "**Answer**: Yes, there is a distinction between the verified checkmarks for companies and blue verified checkmarks for individuals. The code snippet provided mentions \"Blue-verified account boost\" which indicates that there is a separate category for blue verified accounts. Typically, blue verified checkmarks are used to indicate notable individuals, while verified checkmarks are for companies or organizations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
